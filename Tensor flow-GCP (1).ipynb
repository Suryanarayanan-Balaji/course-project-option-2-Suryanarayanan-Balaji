{"cells": [{"cell_type": "code", "execution_count": 1, "id": "e2664dbb", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "/opt/conda/miniconda3/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5)\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"}], "source": "#importing libraries\n\nimport findspark\nimport pyspark\nimport pyspark.sql.functions as F\nimport pyspark\nfrom pyspark.sql import SparkSession, SQLContext\nfrom pyspark.ml import Pipeline,Transformer\nfrom pyspark.ml.feature import Imputer,StandardScaler,StringIndexer,OneHotEncoder, VectorAssembler\n\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\nimport numpy as np\n\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator"}, {"cell_type": "code", "execution_count": 2, "id": "ee344afe", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n22/11/29 01:45:59 INFO org.apache.spark.SparkEnv: Registering MapOutputTracker\n22/11/29 01:45:59 INFO org.apache.spark.SparkEnv: Registering BlockManagerMaster\n22/11/29 01:45:59 INFO org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n22/11/29 01:45:59 INFO org.apache.spark.SparkEnv: Registering OutputCommitCoordinator\n"}], "source": "#creating spark session\nfindspark.init()\nfindspark.find()\n\nspark = SparkSession.builder \\\n    .master(\"local[*]\") \\\n    .appName(\"MQTT\") \\\n    .getOrCreate()\n\nspark = SparkSession.builder.appName(\"mqttProject\").getOrCreate()\nsc    = spark.sparkContext\n\nsqlContext = SQLContext(sc)"}, {"cell_type": "code", "execution_count": 3, "id": "d7efff22", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "test = spark.read.csv( (\"gs://dataproc-staging-us-west3-650974721448-eojcphee/test30_augmented.csv\"),header=True, inferSchema= True)\ntrain = spark.read.csv( (\"gs://dataproc-staging-us-west3-650974721448-eojcphee/train70_augmented.csv\"),header=True, inferSchema= True)\nDF = train.union(test)\nDF = DF.toDF(*(c.replace('.', '_') for c in DF.columns))\ntrain = train.toDF(*(c.replace('.', '_') for c in train.columns))\ntest = test.toDF(*(c.replace('.', '_') for c in test.columns))\ntrain = train.drop(\"mqtt_hdrflags\", \"tcp_flags\", 'mqtt_conack_flags','mqtt_conflags','mqtt_msg',\n        'mqtt_protoname')\ntest = test.drop(\"mqtt_hdrflags\", \"tcp_flags\", 'mqtt_conack_flags','mqtt_conflags','mqtt_msg',\n        'mqtt_protoname')"}, {"cell_type": "code", "execution_count": 4, "id": "781610ac-4cb0-498e-87e3-58751138555f", "metadata": {}, "outputs": [], "source": "train = train.limit(1400)\ntest =  test.limit(600)"}, {"cell_type": "code", "execution_count": 5, "id": "cd255985", "metadata": {}, "outputs": [], "source": "numeric_features = [feature[0] for feature in DF.dtypes if feature[1] not in ('string')]\nstring_features = [feature[0] for feature in DF.dtypes if feature[1] in ('string')]\nto_drop =  [\"mqtt_conflag_cleansess\",\"mqtt_proto_len\",\"mqtt_conflag_passwd\",\"mqtt_qos\"]"}, {"cell_type": "code", "execution_count": 6, "id": "a87f0943", "metadata": {}, "outputs": [], "source": "col_names = ['tcp_time_delta','tcp_len','mqtt_conack_flags','mqtt_conack_flags_reserved','mqtt_conack_flags_sp',\n 'mqtt_conack_val','mqtt_conflag_cleansess','mqtt_conflag_passwd','mqtt_conflag_qos','mqtt_conflag_reserved',\n 'mqtt_conflag_retain','mqtt_conflag_uname','mqtt_conflag_willflag','mqtt_conflags','mqtt_dupflag', \n 'mqtt_kalive', 'mqtt_len','mqtt_msg','mqtt_msgid', 'mqtt_msgtype', 'mqtt_proto_len', 'mqtt_qos', 'mqtt_retain',\n 'mqtt_sub_qos', 'mqtt_suback_qos', 'mqtt_ver', 'mqtt_willmsg', 'mqtt_willmsg_len', 'mqtt_willtopic', 'mqtt_willtopic_len',\n 'target']\n\n# nominal_cols = ['mqtt_conack_flags','mqtt_conflags', 'mqtt_msg', 'mqtt_protoname']\nnominal_cols = []\n\ncontinuous_cols = ['tcp_time_delta', 'tcp_len', 'mqtt_conack_flags_reserved', 'mqtt_conack_flags_sp', 'mqtt_conack_val',\n 'mqtt_conflag_cleansess', 'mqtt_conflag_passwd', 'mqtt_conflag_qos', 'mqtt_conflag_reserved', 'mqtt_conflag_retain',\n 'mqtt_conflag_uname', 'mqtt_conflag_willflag', 'mqtt_dupflag', 'mqtt_kalive', 'mqtt_len', 'mqtt_msgid',\n 'mqtt_msgtype', 'mqtt_proto_len', 'mqtt_qos', 'mqtt_retain', 'mqtt_sub_qos', 'mqtt_suback_qos', 'mqtt_ver',\n 'mqtt_willmsg', 'mqtt_willmsg_len', 'mqtt_willtopic', 'mqtt_willtopic_len']"}, {"cell_type": "code", "execution_count": 7, "id": "2f9a99b3", "metadata": {}, "outputs": [], "source": "class OutcomeCreater_binary(Transformer): # this defines a transformer that creates the outcome column\n    \n    def __init__(self):\n        super().__init__()\n  \n    def _transform(self, dataset):\n        label_to_binary = udf(lambda name: 0.0 if name == 'legitimate' else 1.0)\n        output_df = dataset.withColumn('outcome', label_to_binary(col('target'))).drop(\"target\")  \n        output_df = output_df.withColumn('outcome', col('outcome').cast(DoubleType()))\n        return output_df\n    \nclass OutcomeCreater_multi(Transformer): # this defines a transformer that creates the outcome column\n    \n    def __init__(self):\n        super().__init__()\n  \n    def _transform(self, dataset):\n        label_to_multiple = udf(lambda name: 0.0 if name == 'legitimate' else (1.0 if name == \"flood\" else(2.0 if name == \"dos\" else(3.0 if name == \"bruteforce\" else(4.0 if name == \"slowite\" else (5.0))))))\n        output_df = dataset.withColumn('outcome', label_to_multiple(col('target'))).drop(\"target\")  \n        output_df = output_df.withColumn('outcome', col('outcome').cast(DoubleType()))\n        return output_df\n        \nclass FeatureTypeCaster(Transformer): # this transformer will cast the columns as appropriate types  \n    def __init__(self):\n        super().__init__()\n\n    def _transform(self, dataset):\n        output_df = dataset\n        for col_name in continuous_cols:\n            output_df = output_df.withColumn(col_name,col(col_name).cast(DoubleType()))\n\n        return output_df\n    \nclass ColumnDropper(Transformer): # this transformer drops unnecessary columns\n    def __init__(self, columns_to_drop = None):\n        super().__init__()\n        self.columns_to_drop=columns_to_drop\n    def _transform(self, dataset):\n        output_df = dataset\n        for col_name in self.columns_to_drop:\n            output_df = output_df.drop(col_name)\n            \n        return output_df\n    \ndef get_preprocess_pipeline(classification):\n    # Stage where columns are casted as appropriate types\n    stage_typecaster = FeatureTypeCaster()\n\n    # Stage where nominal columns are transformed to index columns using StringIndexer\n    nominal_id_cols = [x+\"_index\" for x in nominal_cols]\n    nominal_onehot_cols = [x+\"_encoded\" for x in nominal_cols]\n    stage_nominal_indexer = StringIndexer(inputCols = nominal_cols, outputCols = nominal_id_cols )\n    \n    # Stage where the index columns are further transformed using OneHotEncoder\n    stage_nominal_onehot_encoder = OneHotEncoder(inputCols=nominal_id_cols, outputCols=nominal_onehot_cols)\n\n    # Stage where all relevant features are assembled into a vector (and dropping a few)\n    feature_cols = continuous_cols+nominal_onehot_cols\n    corelated_cols_to_remove = to_drop\n    \n    for col_name in corelated_cols_to_remove:\n        feature_cols.remove(col_name)\n    stage_vector_assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"vectorized_features\")\n\n    # Stage where we scale the columns\n    stage_scaler = StandardScaler(inputCol= 'vectorized_features', outputCol= 'features')\n    \n\n    # Stage for creating the outcome column representing whether there is attack\n    if(classification == \"binary\"): \n        stage_outcome = OutcomeCreater_binary()\n    else:\n        stage_outcome = OutcomeCreater_multi()\n\n    # Removing all unnecessary columbs, only keeping the 'features' and 'outcome' columns\n    stage_column_dropper = ColumnDropper(columns_to_drop = nominal_cols+nominal_id_cols+\n        nominal_onehot_cols + continuous_cols + ['vectorized_features'])\n    \n    pipeline = Pipeline(stages=[stage_typecaster,stage_nominal_indexer,stage_nominal_onehot_encoder,\n        stage_vector_assembler,stage_scaler,stage_outcome,stage_column_dropper])\n    \n    return pipeline "}, {"cell_type": "markdown", "id": "8c8933f4", "metadata": {}, "source": "### Multiclass classification"}, {"cell_type": "code", "execution_count": 8, "id": "869a08b6", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "22/11/29 01:47:10 WARN org.apache.spark.sql.catalyst.util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n                                                                                \r"}], "source": "preprocess_pipeline = get_preprocess_pipeline(\"multi\")\npreprocess_pipeline_model = preprocess_pipeline.fit(train)\n\ntrain_df = preprocess_pipeline_model.transform(train)\ntest_df = preprocess_pipeline_model.transform(test)"}, {"cell_type": "code", "execution_count": 9, "id": "60bbd833", "metadata": {}, "outputs": [], "source": "# train_df= train_df.limit(1000)\n# test_df = test_df.limit(400)"}, {"cell_type": "code", "execution_count": 10, "id": "28e9367c", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 10:==========================================>             (13 + 4) / 17]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+-------+\n|            features|outcome|\n+--------------------+-------+\n|(23,[0,1,12,14],[...|    0.0|\n|(23,[0],[4.436988...|    3.0|\n|(23,[0],[1.774795...|    1.0|\n|(23,[0],[1.774795...|    4.0|\n|(23,[0,1,12,14],[...|    1.0|\n|(23,[0,1,12,14],[...|    0.0|\n|(23,[0,1,12,14],[...|    0.0|\n|(23,[0],[2.440343...|    3.0|\n|(23,[0,1,12,14],[...|    0.0|\n|(23,[0,1,8,11,12,...|    3.0|\n|(23,[1,12,13,14],...|    2.0|\n|(23,[0,1,12,14],[...|    0.0|\n|(23,[0,1,12,14],[...|    0.0|\n|(23,[0],[2.795302...|    5.0|\n|(23,[0],[4.436988...|    2.0|\n+--------------------+-------+\nonly showing top 15 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "train_df.show(15)"}, {"cell_type": "code", "execution_count": 11, "id": "76a404a2", "metadata": {}, "outputs": [], "source": "to_array = udf(lambda v: v.toArray().tolist(), ArrayType(FloatType()))\n\ndf_train = train_df\ndf_validate,df_test = test_df.randomSplit([0.5,0.5])"}, {"cell_type": "code", "execution_count": 12, "id": "b015f1c7", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+-------+\n|            features|outcome|\n+--------------------+-------+\n|(23,[0,1,12,14],[...|    0.0|\n|(23,[0],[4.436988...|    3.0|\n|(23,[0],[1.774795...|    1.0|\n|(23,[0],[1.774795...|    4.0|\n|(23,[0,1,12,14],[...|    1.0|\n|(23,[0,1,12,14],[...|    0.0|\n|(23,[0,1,12,14],[...|    0.0|\n|(23,[0],[2.440343...|    3.0|\n|(23,[0,1,12,14],[...|    0.0|\n|(23,[0,1,8,11,12,...|    3.0|\n|(23,[1,12,13,14],...|    2.0|\n|(23,[0,1,12,14],[...|    0.0|\n|(23,[0,1,12,14],[...|    0.0|\n|(23,[0],[2.795302...|    5.0|\n|(23,[0],[4.436988...|    2.0|\n+--------------------+-------+\nonly showing top 15 rows\n\n"}], "source": "df_train.show(15)"}, {"cell_type": "code", "execution_count": 13, "id": "10799ce8", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "/opt/conda/miniconda3/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5)\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"}], "source": "df_train_pandas = df_train.withColumn('features', to_array('features')).toPandas()"}, {"cell_type": "code", "execution_count": 14, "id": "fc8da4f9", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "/opt/conda/miniconda3/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5)\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"}], "source": "df_validate_pandas = df_validate.withColumn('features', to_array('features')).toPandas()\ndf_test_pandas = df_test.withColumn('features', to_array('features')).toPandas()"}, {"cell_type": "code", "execution_count": 15, "id": "3e44ec27-5def-4296-bdc0-965b745b3d8b", "metadata": {}, "outputs": [], "source": "# pip install tensorflow"}, {"cell_type": "code", "execution_count": 16, "id": "53f4132a", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "2022-11-29 01:47:19.151499: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-11-29 01:47:19.335629: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2022-11-29 01:47:19.335670: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2022-11-29 01:47:20.158781: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n2022-11-29 01:47:20.158913: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n2022-11-29 01:47:20.158926: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n2022-11-29 01:47:21.401374: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n2022-11-29 01:47:21.401416: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n2022-11-29 01:47:21.401444: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cluster-0932-m): /proc/driver/nvidia/version does not exist\n2022-11-29 01:47:21.401876: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"}], "source": "import tensorflow as tf\nfrom tensorflow import keras \n\n# Converting the pandas DataFrame to tensors\n# Note we are using 3 data sets train, validate, test\n\nx_train = tf.constant(np.array(df_train_pandas['features'].values.tolist()))\ny_train = tf.constant(np.array(df_train_pandas['outcome'].values.tolist()))\n\nx_validate = tf.constant(np.array(df_validate_pandas['features'].values.tolist()))\ny_validate = tf.constant(np.array(df_validate_pandas['outcome'].values.tolist()))\n\n\nx_test = tf.constant(np.array(df_test_pandas['features'].values.tolist()))\ny_test = tf.constant(np.array(df_test_pandas['outcome'].values.tolist()))"}, {"cell_type": "markdown", "id": "32f8deee", "metadata": {}, "source": "### Shallow NN"}, {"cell_type": "code", "execution_count": 17, "id": "3d86794f", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Epoch 1/20\n44/44 - 1s - loss: 1.6856 - sparse_categorical_accuracy: 0.4757 - val_loss: 1.5728 - val_sparse_categorical_accuracy: 0.4320 - 822ms/epoch - 19ms/step\nEpoch 2/20\n44/44 - 0s - loss: 1.4877 - sparse_categorical_accuracy: 0.4986 - val_loss: 1.3901 - val_sparse_categorical_accuracy: 0.4932 - 122ms/epoch - 3ms/step\nEpoch 3/20\n44/44 - 0s - loss: 1.3551 - sparse_categorical_accuracy: 0.5521 - val_loss: 1.2726 - val_sparse_categorical_accuracy: 0.5816 - 131ms/epoch - 3ms/step\nEpoch 4/20\n44/44 - 0s - loss: 1.2656 - sparse_categorical_accuracy: 0.5850 - val_loss: 1.1938 - val_sparse_categorical_accuracy: 0.6020 - 117ms/epoch - 3ms/step\nEpoch 5/20\n44/44 - 0s - loss: 1.2036 - sparse_categorical_accuracy: 0.5943 - val_loss: 1.1403 - val_sparse_categorical_accuracy: 0.6054 - 117ms/epoch - 3ms/step\nEpoch 6/20\n44/44 - 0s - loss: 1.1596 - sparse_categorical_accuracy: 0.5950 - val_loss: 1.1032 - val_sparse_categorical_accuracy: 0.6054 - 129ms/epoch - 3ms/step\nEpoch 7/20\n44/44 - 0s - loss: 1.1273 - sparse_categorical_accuracy: 0.5986 - val_loss: 1.0766 - val_sparse_categorical_accuracy: 0.6156 - 127ms/epoch - 3ms/step\nEpoch 8/20\n44/44 - 0s - loss: 1.1036 - sparse_categorical_accuracy: 0.6114 - val_loss: 1.0570 - val_sparse_categorical_accuracy: 0.6156 - 126ms/epoch - 3ms/step\nEpoch 9/20\n44/44 - 0s - loss: 1.0860 - sparse_categorical_accuracy: 0.6143 - val_loss: 1.0420 - val_sparse_categorical_accuracy: 0.6190 - 118ms/epoch - 3ms/step\nEpoch 10/20\n44/44 - 0s - loss: 1.0725 - sparse_categorical_accuracy: 0.6171 - val_loss: 1.0302 - val_sparse_categorical_accuracy: 0.6293 - 124ms/epoch - 3ms/step\nEpoch 11/20\n44/44 - 0s - loss: 1.0618 - sparse_categorical_accuracy: 0.6214 - val_loss: 1.0206 - val_sparse_categorical_accuracy: 0.6293 - 121ms/epoch - 3ms/step\nEpoch 12/20\n44/44 - 0s - loss: 1.0531 - sparse_categorical_accuracy: 0.6221 - val_loss: 1.0126 - val_sparse_categorical_accuracy: 0.6293 - 120ms/epoch - 3ms/step\nEpoch 13/20\n44/44 - 0s - loss: 1.0457 - sparse_categorical_accuracy: 0.6229 - val_loss: 1.0057 - val_sparse_categorical_accuracy: 0.6293 - 124ms/epoch - 3ms/step\nEpoch 14/20\n44/44 - 0s - loss: 1.0392 - sparse_categorical_accuracy: 0.6229 - val_loss: 0.9999 - val_sparse_categorical_accuracy: 0.6327 - 115ms/epoch - 3ms/step\nEpoch 15/20\n44/44 - 0s - loss: 1.0335 - sparse_categorical_accuracy: 0.6236 - val_loss: 0.9947 - val_sparse_categorical_accuracy: 0.6327 - 127ms/epoch - 3ms/step\nEpoch 16/20\n44/44 - 0s - loss: 1.0285 - sparse_categorical_accuracy: 0.6250 - val_loss: 0.9902 - val_sparse_categorical_accuracy: 0.6361 - 114ms/epoch - 3ms/step\nEpoch 17/20\n44/44 - 0s - loss: 1.0240 - sparse_categorical_accuracy: 0.6257 - val_loss: 0.9861 - val_sparse_categorical_accuracy: 0.6361 - 119ms/epoch - 3ms/step\nEpoch 18/20\n44/44 - 0s - loss: 1.0199 - sparse_categorical_accuracy: 0.6264 - val_loss: 0.9825 - val_sparse_categorical_accuracy: 0.6361 - 120ms/epoch - 3ms/step\nEpoch 19/20\n44/44 - 0s - loss: 1.0163 - sparse_categorical_accuracy: 0.6264 - val_loss: 0.9794 - val_sparse_categorical_accuracy: 0.6361 - 121ms/epoch - 3ms/step\nEpoch 20/20\n44/44 - 0s - loss: 1.0130 - sparse_categorical_accuracy: 0.6271 - val_loss: 0.9766 - val_sparse_categorical_accuracy: 0.6361 - 122ms/epoch - 3ms/step\n"}, {"data": {"text/plain": "<keras.callbacks.History at 0x7f1c143d6730>"}, "execution_count": 17, "metadata": {}, "output_type": "execute_result"}], "source": "import datetime\nmodel_multiclass = keras.Sequential( [keras.layers.Dense(30,activation='relu'),\n                           keras.layers.Dense(6)] )\n\nmodel_multiclass.compile(optimizer = 'sgd',\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=[keras.metrics.SparseCategoricalAccuracy()])\n\nlog_dir = \"logss/multiiclassfin/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n\nmodel_multiclass.fit(x_train,y_train, epochs = 20,validation_data=(x_validate,y_validate),verbose = 2, callbacks=[tensorboard_callback])"}, {"cell_type": "markdown", "id": "dd34b9b2", "metadata": {}, "source": "#### Hyper parameter tuning with cross validation"}, {"cell_type": "markdown", "id": "415d5c35", "metadata": {}, "source": "##### Shuffling"}, {"cell_type": "code", "execution_count": 18, "id": "2f01627a", "metadata": {}, "outputs": [], "source": "import tensorflow as tf\nfrom tensorflow import keras \ntrain = tf.concat([x_train,tf.reshape(y_train,[-1,1])],1)\ntrain_shuffle = tf.random.shuffle(train)\nx_train_shuffle = train_shuffle[:,0:tf.shape(x_train)[1]]\ny_train_shuffle = train_shuffle[:,tf.shape(x_train)[1]]"}, {"cell_type": "markdown", "id": "88498a07", "metadata": {}, "source": "##### Hyperparameters"}, {"cell_type": "code", "execution_count": 19, "id": "afc351da", "metadata": {}, "outputs": [], "source": "from tensorboard.plugins.hparams import api as hp\n\nHP_WIDTH = hp.HParam('NN_width', hp.Discrete([20,30,40]))\nHP_DEPTH = hp.HParam('NN_depth', hp.Discrete([1,2]))\n\n\nwith tf.summary.create_file_writer('logs1483/hparams_tuning').as_default():\n  hp.hparams_config(\n    hparams=[HP_WIDTH, HP_DEPTH],\n    metrics=[hp.Metric('Accuracy')],\n  )"}, {"cell_type": "markdown", "id": "28732246", "metadata": {}, "source": "##### CrossValidation"}, {"cell_type": "code", "execution_count": 20, "id": "e8494aa0", "metadata": {}, "outputs": [], "source": "def CV_model(hparams,logdir, k, current_best, d, w):\n    indiceslist = []\n    \n    for i in range(k-1):\n        indices = tf.range(i * ((tf.shape(x_train_shuffle)[0])//k), (i + 1)* ((tf.shape(x_train_shuffle)[0])//k),1).numpy().tolist()\n        indiceslist.append([indices])\n        \n    accuracy = 0\n    # combining whatever remaining after k-1 splits (to account if length of dataset is not divisible by k)\n    \n    indices = tf.range((k-1) * ((tf.shape(x_train_shuffle)[0])//k), (tf.shape(x_train_shuffle)[0]),1).numpy().tolist()\n    \n    indiceslist.append([indices]) ## indiceslist to divide train and validate\n    \n    for i in range(k):\n        print(\"\\nSplit no\",i+1)\n        model = keras.Sequential()\n        for _ in range(hparams[HP_DEPTH]):\n            model.add(keras.layers.Dense(hparams[HP_WIDTH],activation='relu'))\n        model.add(keras.layers.Dense(6))\n        model.compile(\n          optimizer=keras.optimizers.SGD(),\n          loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n          metrics=[keras.metrics.SparseCategoricalAccuracy()])\n        \n        b = indiceslist[i][0] \n        a = [int(item) for item in b]\n\n        x_validate = tf.gather(x_train_shuffle,a)\n\n        y_validate = tf.gather(y_train_shuffle,a)\n        \n        z = []\n        \n        for j in range(k):\n            \n            if j != i:                     ## Make sure validation and train set are different\n                z =  z + indiceslist[j][0]\n                \n        a = [int(item) for item in z]\n        \n        x_train = tf.gather(x_train_shuffle, a)\n        y_train = tf.gather(y_train_shuffle, a)\n        \n        print(\"\\nTraining\")\n        \n        history = model.fit(x_train, y_train, epochs= 10,validation_data = (x_validate,y_validate), verbose = 2)\n        if np.max(history.history[\"val_sparse_categorical_accuracy\"]) > current_best:\n                  current_best = np.max(history.history[\"val_sparse_categorical_accuracy\"])\n                  d = hparams[HP_DEPTH]\n                  w = hparams[HP_WIDTH]\n        accuracy = accuracy + np.max(history.history[\"val_sparse_categorical_accuracy\"])\n    \n    return accuracy/k, d, w, current_best"}, {"cell_type": "code", "execution_count": 21, "id": "4685a60f", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "--- Starting trial: run-WIDTH20-DEPTH1\n{'NN_width': 20, 'NN_depth': 1}\n\nSplit no 1\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.9153 - sparse_categorical_accuracy: 0.1895 - val_loss: 1.8579 - val_sparse_categorical_accuracy: 0.1695 - 582ms/epoch - 19ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.7572 - sparse_categorical_accuracy: 0.4411 - val_loss: 1.7239 - val_sparse_categorical_accuracy: 0.4742 - 82ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.6286 - sparse_categorical_accuracy: 0.5161 - val_loss: 1.6168 - val_sparse_categorical_accuracy: 0.4914 - 79ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.5262 - sparse_categorical_accuracy: 0.5257 - val_loss: 1.5317 - val_sparse_categorical_accuracy: 0.5043 - 87ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.4452 - sparse_categorical_accuracy: 0.5321 - val_loss: 1.4606 - val_sparse_categorical_accuracy: 0.5150 - 81ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.3779 - sparse_categorical_accuracy: 0.5396 - val_loss: 1.4026 - val_sparse_categorical_accuracy: 0.5215 - 83ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.3234 - sparse_categorical_accuracy: 0.5514 - val_loss: 1.3540 - val_sparse_categorical_accuracy: 0.5601 - 81ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.2781 - sparse_categorical_accuracy: 0.5857 - val_loss: 1.3151 - val_sparse_categorical_accuracy: 0.5751 - 82ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.2414 - sparse_categorical_accuracy: 0.5878 - val_loss: 1.2834 - val_sparse_categorical_accuracy: 0.5773 - 82ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.2121 - sparse_categorical_accuracy: 0.5921 - val_loss: 1.2583 - val_sparse_categorical_accuracy: 0.5794 - 79ms/epoch - 3ms/step\n\nSplit no 2\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.9487 - sparse_categorical_accuracy: 0.2195 - val_loss: 1.8507 - val_sparse_categorical_accuracy: 0.1953 - 554ms/epoch - 18ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.7187 - sparse_categorical_accuracy: 0.3865 - val_loss: 1.6499 - val_sparse_categorical_accuracy: 0.4785 - 77ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.5626 - sparse_categorical_accuracy: 0.5043 - val_loss: 1.5113 - val_sparse_categorical_accuracy: 0.5021 - 80ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.4511 - sparse_categorical_accuracy: 0.5375 - val_loss: 1.4116 - val_sparse_categorical_accuracy: 0.5472 - 84ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.3684 - sparse_categorical_accuracy: 0.5642 - val_loss: 1.3371 - val_sparse_categorical_accuracy: 0.5408 - 80ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.3051 - sparse_categorical_accuracy: 0.5685 - val_loss: 1.2773 - val_sparse_categorical_accuracy: 0.5622 - 81ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.2556 - sparse_categorical_accuracy: 0.5899 - val_loss: 1.2327 - val_sparse_categorical_accuracy: 0.5944 - 85ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.2180 - sparse_categorical_accuracy: 0.5985 - val_loss: 1.1966 - val_sparse_categorical_accuracy: 0.5987 - 80ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.1875 - sparse_categorical_accuracy: 0.6017 - val_loss: 1.1661 - val_sparse_categorical_accuracy: 0.5987 - 79ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.1633 - sparse_categorical_accuracy: 0.6039 - val_loss: 1.1422 - val_sparse_categorical_accuracy: 0.6030 - 79ms/epoch - 3ms/step\n\nSplit no 3\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.9029 - sparse_categorical_accuracy: 0.3509 - val_loss: 1.7156 - val_sparse_categorical_accuracy: 0.5620 - 556ms/epoch - 19ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.7084 - sparse_categorical_accuracy: 0.5215 - val_loss: 1.5845 - val_sparse_categorical_accuracy: 0.5620 - 89ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.5749 - sparse_categorical_accuracy: 0.5236 - val_loss: 1.4863 - val_sparse_categorical_accuracy: 0.5684 - 81ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.4778 - sparse_categorical_accuracy: 0.5365 - val_loss: 1.4125 - val_sparse_categorical_accuracy: 0.5726 - 79ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.4060 - sparse_categorical_accuracy: 0.5526 - val_loss: 1.3538 - val_sparse_categorical_accuracy: 0.5876 - 88ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.3486 - sparse_categorical_accuracy: 0.5601 - val_loss: 1.3128 - val_sparse_categorical_accuracy: 0.5897 - 81ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.3080 - sparse_categorical_accuracy: 0.5665 - val_loss: 1.2774 - val_sparse_categorical_accuracy: 0.5983 - 79ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.2727 - sparse_categorical_accuracy: 0.5719 - val_loss: 1.2488 - val_sparse_categorical_accuracy: 0.6004 - 87ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.2430 - sparse_categorical_accuracy: 0.5794 - val_loss: 1.2254 - val_sparse_categorical_accuracy: 0.6026 - 79ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.2174 - sparse_categorical_accuracy: 0.5826 - val_loss: 1.2045 - val_sparse_categorical_accuracy: 0.6047 - 77ms/epoch - 3ms/step\n--- Starting trial: run-WIDTH20-DEPTH2\n{'NN_width': 20, 'NN_depth': 2}\n\nSplit no 1\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.7153 - sparse_categorical_accuracy: 0.4154 - val_loss: 1.6447 - val_sparse_categorical_accuracy: 0.5043 - 639ms/epoch - 21ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.5692 - sparse_categorical_accuracy: 0.5514 - val_loss: 1.5200 - val_sparse_categorical_accuracy: 0.5601 - 88ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.4496 - sparse_categorical_accuracy: 0.5942 - val_loss: 1.4228 - val_sparse_categorical_accuracy: 0.5773 - 79ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.3558 - sparse_categorical_accuracy: 0.5996 - val_loss: 1.3449 - val_sparse_categorical_accuracy: 0.5858 - 81ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.2804 - sparse_categorical_accuracy: 0.6028 - val_loss: 1.2848 - val_sparse_categorical_accuracy: 0.5880 - 81ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.2237 - sparse_categorical_accuracy: 0.6060 - val_loss: 1.2387 - val_sparse_categorical_accuracy: 0.5901 - 89ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.1807 - sparse_categorical_accuracy: 0.6071 - val_loss: 1.2078 - val_sparse_categorical_accuracy: 0.5901 - 80ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.1519 - sparse_categorical_accuracy: 0.6081 - val_loss: 1.1846 - val_sparse_categorical_accuracy: 0.5923 - 81ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.1299 - sparse_categorical_accuracy: 0.6092 - val_loss: 1.1659 - val_sparse_categorical_accuracy: 0.5923 - 89ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.1127 - sparse_categorical_accuracy: 0.6092 - val_loss: 1.1497 - val_sparse_categorical_accuracy: 0.5923 - 80ms/epoch - 3ms/step\n\nSplit no 2\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.8334 - sparse_categorical_accuracy: 0.2677 - val_loss: 1.7560 - val_sparse_categorical_accuracy: 0.5193 - 626ms/epoch - 21ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.6988 - sparse_categorical_accuracy: 0.5332 - val_loss: 1.6412 - val_sparse_categorical_accuracy: 0.5258 - 84ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.5980 - sparse_categorical_accuracy: 0.5343 - val_loss: 1.5494 - val_sparse_categorical_accuracy: 0.5215 - 84ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.5155 - sparse_categorical_accuracy: 0.5321 - val_loss: 1.4767 - val_sparse_categorical_accuracy: 0.5172 - 80ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.4491 - sparse_categorical_accuracy: 0.5310 - val_loss: 1.4230 - val_sparse_categorical_accuracy: 0.5172 - 86ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.3983 - sparse_categorical_accuracy: 0.5310 - val_loss: 1.3770 - val_sparse_categorical_accuracy: 0.5172 - 84ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.3550 - sparse_categorical_accuracy: 0.5353 - val_loss: 1.3408 - val_sparse_categorical_accuracy: 0.5258 - 78ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.3207 - sparse_categorical_accuracy: 0.5407 - val_loss: 1.3081 - val_sparse_categorical_accuracy: 0.5258 - 79ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.2896 - sparse_categorical_accuracy: 0.5418 - val_loss: 1.2787 - val_sparse_categorical_accuracy: 0.5258 - 87ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.2626 - sparse_categorical_accuracy: 0.5482 - val_loss: 1.2524 - val_sparse_categorical_accuracy: 0.5365 - 84ms/epoch - 3ms/step\n\nSplit no 3\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.8348 - sparse_categorical_accuracy: 0.2414 - val_loss: 1.7874 - val_sparse_categorical_accuracy: 0.4274 - 625ms/epoch - 21ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.7236 - sparse_categorical_accuracy: 0.5333 - val_loss: 1.7064 - val_sparse_categorical_accuracy: 0.5556 - 81ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.6554 - sparse_categorical_accuracy: 0.5687 - val_loss: 1.6483 - val_sparse_categorical_accuracy: 0.5684 - 93ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.6034 - sparse_categorical_accuracy: 0.5676 - val_loss: 1.6029 - val_sparse_categorical_accuracy: 0.5684 - 80ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.5601 - sparse_categorical_accuracy: 0.5676 - val_loss: 1.5627 - val_sparse_categorical_accuracy: 0.5684 - 81ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.5223 - sparse_categorical_accuracy: 0.5687 - val_loss: 1.5267 - val_sparse_categorical_accuracy: 0.5748 - 87ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.4886 - sparse_categorical_accuracy: 0.5719 - val_loss: 1.4959 - val_sparse_categorical_accuracy: 0.5748 - 80ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.4593 - sparse_categorical_accuracy: 0.5719 - val_loss: 1.4676 - val_sparse_categorical_accuracy: 0.5748 - 80ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.4324 - sparse_categorical_accuracy: 0.5719 - val_loss: 1.4403 - val_sparse_categorical_accuracy: 0.5726 - 87ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.4070 - sparse_categorical_accuracy: 0.5719 - val_loss: 1.4164 - val_sparse_categorical_accuracy: 0.5748 - 80ms/epoch - 3ms/step\n--- Starting trial: run-WIDTH30-DEPTH1\n{'NN_width': 30, 'NN_depth': 1}\n\nSplit no 1\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.9073 - sparse_categorical_accuracy: 0.2463 - val_loss: 1.8281 - val_sparse_categorical_accuracy: 0.2382 - 569ms/epoch - 19ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.7496 - sparse_categorical_accuracy: 0.2687 - val_loss: 1.6965 - val_sparse_categorical_accuracy: 0.2704 - 80ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.6268 - sparse_categorical_accuracy: 0.5332 - val_loss: 1.5915 - val_sparse_categorical_accuracy: 0.5794 - 80ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.5267 - sparse_categorical_accuracy: 0.5953 - val_loss: 1.5032 - val_sparse_categorical_accuracy: 0.5751 - 88ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.4429 - sparse_categorical_accuracy: 0.5974 - val_loss: 1.4299 - val_sparse_categorical_accuracy: 0.5858 - 80ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.3741 - sparse_categorical_accuracy: 0.5985 - val_loss: 1.3685 - val_sparse_categorical_accuracy: 0.5858 - 79ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.3169 - sparse_categorical_accuracy: 0.5974 - val_loss: 1.3179 - val_sparse_categorical_accuracy: 0.5858 - 85ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.2705 - sparse_categorical_accuracy: 0.5964 - val_loss: 1.2771 - val_sparse_categorical_accuracy: 0.5837 - 79ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.2333 - sparse_categorical_accuracy: 0.5964 - val_loss: 1.2430 - val_sparse_categorical_accuracy: 0.5858 - 79ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.2025 - sparse_categorical_accuracy: 0.5974 - val_loss: 1.2154 - val_sparse_categorical_accuracy: 0.5858 - 78ms/epoch - 3ms/step\n\nSplit no 2\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.7690 - sparse_categorical_accuracy: 0.5214 - val_loss: 1.6560 - val_sparse_categorical_accuracy: 0.5172 - 785ms/epoch - 26ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.6121 - sparse_categorical_accuracy: 0.5289 - val_loss: 1.5162 - val_sparse_categorical_accuracy: 0.5150 - 87ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.4896 - sparse_categorical_accuracy: 0.5321 - val_loss: 1.4012 - val_sparse_categorical_accuracy: 0.5365 - 81ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.3925 - sparse_categorical_accuracy: 0.5600 - val_loss: 1.3225 - val_sparse_categorical_accuracy: 0.5601 - 79ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.3222 - sparse_categorical_accuracy: 0.5707 - val_loss: 1.2607 - val_sparse_categorical_accuracy: 0.5665 - 81ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.2664 - sparse_categorical_accuracy: 0.5749 - val_loss: 1.2129 - val_sparse_categorical_accuracy: 0.5794 - 84ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.2239 - sparse_categorical_accuracy: 0.5846 - val_loss: 1.1760 - val_sparse_categorical_accuracy: 0.5944 - 87ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.1899 - sparse_categorical_accuracy: 0.5964 - val_loss: 1.1481 - val_sparse_categorical_accuracy: 0.6030 - 82ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.1642 - sparse_categorical_accuracy: 0.6039 - val_loss: 1.1261 - val_sparse_categorical_accuracy: 0.6073 - 92ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.1436 - sparse_categorical_accuracy: 0.6049 - val_loss: 1.1086 - val_sparse_categorical_accuracy: 0.6094 - 83ms/epoch - 3ms/step\n\nSplit no 3\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.7550 - sparse_categorical_accuracy: 0.3412 - val_loss: 1.6346 - val_sparse_categorical_accuracy: 0.5385 - 557ms/epoch - 19ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.5738 - sparse_categorical_accuracy: 0.5322 - val_loss: 1.4916 - val_sparse_categorical_accuracy: 0.5769 - 79ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.4438 - sparse_categorical_accuracy: 0.5665 - val_loss: 1.3933 - val_sparse_categorical_accuracy: 0.5940 - 82ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.3524 - sparse_categorical_accuracy: 0.5740 - val_loss: 1.3208 - val_sparse_categorical_accuracy: 0.5940 - 89ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.2841 - sparse_categorical_accuracy: 0.5751 - val_loss: 1.2693 - val_sparse_categorical_accuracy: 0.5962 - 82ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.2356 - sparse_categorical_accuracy: 0.5880 - val_loss: 1.2294 - val_sparse_categorical_accuracy: 0.6026 - 85ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.1978 - sparse_categorical_accuracy: 0.6073 - val_loss: 1.1978 - val_sparse_categorical_accuracy: 0.6175 - 86ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.1681 - sparse_categorical_accuracy: 0.6137 - val_loss: 1.1770 - val_sparse_categorical_accuracy: 0.6218 - 88ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.1457 - sparse_categorical_accuracy: 0.6148 - val_loss: 1.1572 - val_sparse_categorical_accuracy: 0.6218 - 85ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.1272 - sparse_categorical_accuracy: 0.6159 - val_loss: 1.1408 - val_sparse_categorical_accuracy: 0.6218 - 82ms/epoch - 3ms/step\n--- Starting trial: run-WIDTH30-DEPTH2\n{'NN_width': 30, 'NN_depth': 2}\n\nSplit no 1\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.9629 - sparse_categorical_accuracy: 0.2099 - val_loss: 1.8305 - val_sparse_categorical_accuracy: 0.2382 - 633ms/epoch - 21ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.7615 - sparse_categorical_accuracy: 0.3822 - val_loss: 1.6885 - val_sparse_categorical_accuracy: 0.5365 - 84ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.6423 - sparse_categorical_accuracy: 0.5546 - val_loss: 1.5974 - val_sparse_categorical_accuracy: 0.5558 - 90ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.5582 - sparse_categorical_accuracy: 0.5653 - val_loss: 1.5252 - val_sparse_categorical_accuracy: 0.5536 - 81ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.4873 - sparse_categorical_accuracy: 0.5632 - val_loss: 1.4625 - val_sparse_categorical_accuracy: 0.5536 - 81ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.4250 - sparse_categorical_accuracy: 0.5621 - val_loss: 1.4058 - val_sparse_categorical_accuracy: 0.5494 - 82ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.3688 - sparse_categorical_accuracy: 0.5535 - val_loss: 1.3559 - val_sparse_categorical_accuracy: 0.5429 - 87ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.3192 - sparse_categorical_accuracy: 0.5525 - val_loss: 1.3136 - val_sparse_categorical_accuracy: 0.5429 - 85ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.2777 - sparse_categorical_accuracy: 0.5535 - val_loss: 1.2762 - val_sparse_categorical_accuracy: 0.5429 - 85ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.2414 - sparse_categorical_accuracy: 0.5525 - val_loss: 1.2441 - val_sparse_categorical_accuracy: 0.5794 - 83ms/epoch - 3ms/step\n\nSplit no 2\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.8598 - sparse_categorical_accuracy: 0.2238 - val_loss: 1.7191 - val_sparse_categorical_accuracy: 0.2639 - 634ms/epoch - 21ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.6583 - sparse_categorical_accuracy: 0.4529 - val_loss: 1.5687 - val_sparse_categorical_accuracy: 0.5923 - 97ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.5328 - sparse_categorical_accuracy: 0.5953 - val_loss: 1.4564 - val_sparse_categorical_accuracy: 0.6052 - 84ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.4328 - sparse_categorical_accuracy: 0.6006 - val_loss: 1.3710 - val_sparse_categorical_accuracy: 0.6073 - 88ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.3566 - sparse_categorical_accuracy: 0.6103 - val_loss: 1.2992 - val_sparse_categorical_accuracy: 0.6202 - 84ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.2928 - sparse_categorical_accuracy: 0.6113 - val_loss: 1.2365 - val_sparse_categorical_accuracy: 0.6180 - 83ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.2390 - sparse_categorical_accuracy: 0.6071 - val_loss: 1.1950 - val_sparse_categorical_accuracy: 0.6202 - 91ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.2021 - sparse_categorical_accuracy: 0.6124 - val_loss: 1.1631 - val_sparse_categorical_accuracy: 0.6202 - 84ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.1735 - sparse_categorical_accuracy: 0.6124 - val_loss: 1.1378 - val_sparse_categorical_accuracy: 0.6202 - 79ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.1502 - sparse_categorical_accuracy: 0.6124 - val_loss: 1.1176 - val_sparse_categorical_accuracy: 0.6202 - 83ms/epoch - 3ms/step\n\nSplit no 3\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.7820 - sparse_categorical_accuracy: 0.3455 - val_loss: 1.7040 - val_sparse_categorical_accuracy: 0.5064 - 626ms/epoch - 21ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.6751 - sparse_categorical_accuracy: 0.4657 - val_loss: 1.6107 - val_sparse_categorical_accuracy: 0.5064 - 125ms/epoch - 4ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.5807 - sparse_categorical_accuracy: 0.5011 - val_loss: 1.5242 - val_sparse_categorical_accuracy: 0.5449 - 85ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.4948 - sparse_categorical_accuracy: 0.5408 - val_loss: 1.4485 - val_sparse_categorical_accuracy: 0.5470 - 85ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.4201 - sparse_categorical_accuracy: 0.5429 - val_loss: 1.3824 - val_sparse_categorical_accuracy: 0.5491 - 83ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.3573 - sparse_categorical_accuracy: 0.5451 - val_loss: 1.3271 - val_sparse_categorical_accuracy: 0.5513 - 82ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.3039 - sparse_categorical_accuracy: 0.5472 - val_loss: 1.2811 - val_sparse_categorical_accuracy: 0.5513 - 82ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.2617 - sparse_categorical_accuracy: 0.5472 - val_loss: 1.2481 - val_sparse_categorical_accuracy: 0.5513 - 87ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.2294 - sparse_categorical_accuracy: 0.5536 - val_loss: 1.2200 - val_sparse_categorical_accuracy: 0.5641 - 81ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.2002 - sparse_categorical_accuracy: 0.5848 - val_loss: 1.1944 - val_sparse_categorical_accuracy: 0.6047 - 80ms/epoch - 3ms/step\n--- Starting trial: run-WIDTH40-DEPTH1\n{'NN_width': 40, 'NN_depth': 1}\n\nSplit no 1\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.8697 - sparse_categorical_accuracy: 0.2398 - val_loss: 1.7381 - val_sparse_categorical_accuracy: 0.4056 - 569ms/epoch - 19ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.6092 - sparse_categorical_accuracy: 0.5621 - val_loss: 1.5284 - val_sparse_categorical_accuracy: 0.5429 - 77ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.4398 - sparse_categorical_accuracy: 0.5707 - val_loss: 1.4099 - val_sparse_categorical_accuracy: 0.5515 - 79ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.3400 - sparse_categorical_accuracy: 0.5749 - val_loss: 1.3319 - val_sparse_categorical_accuracy: 0.5579 - 85ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.2730 - sparse_categorical_accuracy: 0.5814 - val_loss: 1.2765 - val_sparse_categorical_accuracy: 0.5579 - 77ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.2256 - sparse_categorical_accuracy: 0.5835 - val_loss: 1.2367 - val_sparse_categorical_accuracy: 0.5622 - 80ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.1905 - sparse_categorical_accuracy: 0.5942 - val_loss: 1.2055 - val_sparse_categorical_accuracy: 0.5837 - 83ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.1630 - sparse_categorical_accuracy: 0.6039 - val_loss: 1.1797 - val_sparse_categorical_accuracy: 0.5987 - 79ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.1410 - sparse_categorical_accuracy: 0.6135 - val_loss: 1.1599 - val_sparse_categorical_accuracy: 0.6009 - 91ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.1233 - sparse_categorical_accuracy: 0.6146 - val_loss: 1.1445 - val_sparse_categorical_accuracy: 0.6030 - 80ms/epoch - 3ms/step\n\nSplit no 2\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.8593 - sparse_categorical_accuracy: 0.2591 - val_loss: 1.7157 - val_sparse_categorical_accuracy: 0.4120 - 565ms/epoch - 19ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.6497 - sparse_categorical_accuracy: 0.5278 - val_loss: 1.5488 - val_sparse_categorical_accuracy: 0.5365 - 87ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.5101 - sparse_categorical_accuracy: 0.5353 - val_loss: 1.4365 - val_sparse_categorical_accuracy: 0.5343 - 78ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.4141 - sparse_categorical_accuracy: 0.5353 - val_loss: 1.3595 - val_sparse_categorical_accuracy: 0.5408 - 79ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.3458 - sparse_categorical_accuracy: 0.5535 - val_loss: 1.3042 - val_sparse_categorical_accuracy: 0.5536 - 90ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.2961 - sparse_categorical_accuracy: 0.5557 - val_loss: 1.2625 - val_sparse_categorical_accuracy: 0.5536 - 81ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.2580 - sparse_categorical_accuracy: 0.5557 - val_loss: 1.2304 - val_sparse_categorical_accuracy: 0.5536 - 101ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.2286 - sparse_categorical_accuracy: 0.5557 - val_loss: 1.2033 - val_sparse_categorical_accuracy: 0.5558 - 82ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.2043 - sparse_categorical_accuracy: 0.5578 - val_loss: 1.1817 - val_sparse_categorical_accuracy: 0.5773 - 86ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.1842 - sparse_categorical_accuracy: 0.5889 - val_loss: 1.1629 - val_sparse_categorical_accuracy: 0.5987 - 81ms/epoch - 3ms/step\n\nSplit no 3\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.6521 - sparse_categorical_accuracy: 0.5161 - val_loss: 1.5603 - val_sparse_categorical_accuracy: 0.5534 - 570ms/epoch - 19ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.5054 - sparse_categorical_accuracy: 0.5418 - val_loss: 1.4496 - val_sparse_categorical_accuracy: 0.5641 - 88ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.4006 - sparse_categorical_accuracy: 0.5451 - val_loss: 1.3658 - val_sparse_categorical_accuracy: 0.5598 - 80ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.3203 - sparse_categorical_accuracy: 0.5451 - val_loss: 1.3020 - val_sparse_categorical_accuracy: 0.5662 - 78ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.2588 - sparse_categorical_accuracy: 0.5762 - val_loss: 1.2541 - val_sparse_categorical_accuracy: 0.6090 - 78ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.2125 - sparse_categorical_accuracy: 0.6052 - val_loss: 1.2140 - val_sparse_categorical_accuracy: 0.6132 - 86ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.1762 - sparse_categorical_accuracy: 0.6073 - val_loss: 1.1847 - val_sparse_categorical_accuracy: 0.6154 - 79ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.1493 - sparse_categorical_accuracy: 0.6094 - val_loss: 1.1602 - val_sparse_categorical_accuracy: 0.6175 - 83ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.1269 - sparse_categorical_accuracy: 0.6105 - val_loss: 1.1406 - val_sparse_categorical_accuracy: 0.6175 - 88ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.1091 - sparse_categorical_accuracy: 0.6137 - val_loss: 1.1248 - val_sparse_categorical_accuracy: 0.6175 - 80ms/epoch - 3ms/step\n--- Starting trial: run-WIDTH40-DEPTH2\n{'NN_width': 40, 'NN_depth': 2}\n\nSplit no 1\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.7967 - sparse_categorical_accuracy: 0.2891 - val_loss: 1.6961 - val_sparse_categorical_accuracy: 0.4700 - 623ms/epoch - 21ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.6179 - sparse_categorical_accuracy: 0.5931 - val_loss: 1.5595 - val_sparse_categorical_accuracy: 0.5730 - 82ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.4890 - sparse_categorical_accuracy: 0.5899 - val_loss: 1.4459 - val_sparse_categorical_accuracy: 0.5644 - 89ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.3802 - sparse_categorical_accuracy: 0.5835 - val_loss: 1.3537 - val_sparse_categorical_accuracy: 0.5601 - 80ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.2963 - sparse_categorical_accuracy: 0.5878 - val_loss: 1.2855 - val_sparse_categorical_accuracy: 0.5751 - 84ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.2340 - sparse_categorical_accuracy: 0.5899 - val_loss: 1.2360 - val_sparse_categorical_accuracy: 0.5773 - 86ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.1888 - sparse_categorical_accuracy: 0.5974 - val_loss: 1.2004 - val_sparse_categorical_accuracy: 0.5987 - 88ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.1557 - sparse_categorical_accuracy: 0.6081 - val_loss: 1.1747 - val_sparse_categorical_accuracy: 0.5987 - 82ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.1321 - sparse_categorical_accuracy: 0.6103 - val_loss: 1.1551 - val_sparse_categorical_accuracy: 0.5987 - 83ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.1136 - sparse_categorical_accuracy: 0.6113 - val_loss: 1.1396 - val_sparse_categorical_accuracy: 0.6030 - 84ms/epoch - 3ms/step\n\nSplit no 2\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.7017 - sparse_categorical_accuracy: 0.4914 - val_loss: 1.6044 - val_sparse_categorical_accuracy: 0.4914 - 624ms/epoch - 21ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.5434 - sparse_categorical_accuracy: 0.5096 - val_loss: 1.4709 - val_sparse_categorical_accuracy: 0.4979 - 78ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.4231 - sparse_categorical_accuracy: 0.5161 - val_loss: 1.3694 - val_sparse_categorical_accuracy: 0.5150 - 90ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.3341 - sparse_categorical_accuracy: 0.5268 - val_loss: 1.2923 - val_sparse_categorical_accuracy: 0.5279 - 82ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.2704 - sparse_categorical_accuracy: 0.5396 - val_loss: 1.2426 - val_sparse_categorical_accuracy: 0.5708 - 88ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.2281 - sparse_categorical_accuracy: 0.5878 - val_loss: 1.2042 - val_sparse_categorical_accuracy: 0.6073 - 83ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.1945 - sparse_categorical_accuracy: 0.6092 - val_loss: 1.1741 - val_sparse_categorical_accuracy: 0.6159 - 83ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.1687 - sparse_categorical_accuracy: 0.6092 - val_loss: 1.1495 - val_sparse_categorical_accuracy: 0.6180 - 83ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.1467 - sparse_categorical_accuracy: 0.6156 - val_loss: 1.1276 - val_sparse_categorical_accuracy: 0.6180 - 81ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.1277 - sparse_categorical_accuracy: 0.6178 - val_loss: 1.1095 - val_sparse_categorical_accuracy: 0.6180 - 124ms/epoch - 4ms/step\n\nSplit no 3\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.8662 - sparse_categorical_accuracy: 0.2758 - val_loss: 1.7473 - val_sparse_categorical_accuracy: 0.4979 - 630ms/epoch - 21ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.7024 - sparse_categorical_accuracy: 0.4828 - val_loss: 1.6166 - val_sparse_categorical_accuracy: 0.5641 - 87ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.5777 - sparse_categorical_accuracy: 0.5483 - val_loss: 1.5113 - val_sparse_categorical_accuracy: 0.5897 - 79ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.4751 - sparse_categorical_accuracy: 0.5687 - val_loss: 1.4218 - val_sparse_categorical_accuracy: 0.6026 - 85ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.3876 - sparse_categorical_accuracy: 0.5987 - val_loss: 1.3492 - val_sparse_categorical_accuracy: 0.6154 - 88ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.3177 - sparse_categorical_accuracy: 0.6062 - val_loss: 1.2911 - val_sparse_categorical_accuracy: 0.6175 - 84ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.2619 - sparse_categorical_accuracy: 0.6084 - val_loss: 1.2402 - val_sparse_categorical_accuracy: 0.6175 - 89ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.2154 - sparse_categorical_accuracy: 0.6084 - val_loss: 1.1995 - val_sparse_categorical_accuracy: 0.6175 - 84ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.1788 - sparse_categorical_accuracy: 0.6116 - val_loss: 1.1705 - val_sparse_categorical_accuracy: 0.6175 - 89ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.1515 - sparse_categorical_accuracy: 0.6148 - val_loss: 1.1475 - val_sparse_categorical_accuracy: 0.6175 - 85ms/epoch - 3ms/step\n"}], "source": "k =3 \ncurrent_best = 0\nd,w = 0,0\nfor hp_width in HP_WIDTH.domain.values:\n  for hp_depth in (HP_DEPTH.domain.values):\n    hparams = {\n        HP_WIDTH: hp_width,\n        HP_DEPTH: hp_depth,\n    }\n    run_name = f\"run-WIDTH{int(hparams[HP_WIDTH])}-DEPTH{hparams[HP_DEPTH]}\"\n    print('--- Starting trial: %s' % run_name)\n    print({h.name: hparams[h] for h in hparams})\n\n    run_dir = 'logs1483/hparams_tuning/' + run_name\n    accuracy, d, w, current_best = CV_model(hparams,run_dir, k, current_best, d, w)\n\n    with tf.summary.create_file_writer(run_dir).as_default():\n      hp.hparams(hparams)  # record the values used in this trial\n      tf.summary.scalar(\"Accuracy\", accuracy, step=1)"}, {"cell_type": "markdown", "id": "a7cef0c3", "metadata": {}, "source": "##### Best parameters"}, {"cell_type": "code", "execution_count": 22, "id": "1be04c6c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Tuned Depth for shallow NN =  1\nTuned Widhth for shallow NN =  30\n"}], "source": "print(\"Tuned Depth for shallow NN = \",d)\nprint(\"Tuned Widhth for shallow NN = \",w)"}, {"cell_type": "markdown", "id": "38672de5", "metadata": {}, "source": "#### Tuned Hyper parameters"}, {"cell_type": "code", "execution_count": 23, "id": "ca9d68d5", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Epoch 1/20\n44/44 - 1s - loss: 1.8622 - sparse_categorical_accuracy: 0.2586 - val_loss: 1.6694 - val_sparse_categorical_accuracy: 0.5510 - 592ms/epoch - 13ms/step\nEpoch 2/20\n44/44 - 0s - loss: 1.5765 - sparse_categorical_accuracy: 0.5721 - val_loss: 1.4691 - val_sparse_categorical_accuracy: 0.5578 - 115ms/epoch - 3ms/step\nEpoch 3/20\n44/44 - 0s - loss: 1.4127 - sparse_categorical_accuracy: 0.5729 - val_loss: 1.3529 - val_sparse_categorical_accuracy: 0.5816 - 116ms/epoch - 3ms/step\nEpoch 4/20\n44/44 - 0s - loss: 1.3149 - sparse_categorical_accuracy: 0.5764 - val_loss: 1.2729 - val_sparse_categorical_accuracy: 0.5816 - 120ms/epoch - 3ms/step\nEpoch 5/20\n44/44 - 0s - loss: 1.2478 - sparse_categorical_accuracy: 0.5764 - val_loss: 1.2118 - val_sparse_categorical_accuracy: 0.5918 - 121ms/epoch - 3ms/step\nEpoch 6/20\n44/44 - 0s - loss: 1.1987 - sparse_categorical_accuracy: 0.5886 - val_loss: 1.1649 - val_sparse_categorical_accuracy: 0.5918 - 121ms/epoch - 3ms/step\nEpoch 7/20\n44/44 - 0s - loss: 1.1618 - sparse_categorical_accuracy: 0.5921 - val_loss: 1.1282 - val_sparse_categorical_accuracy: 0.5918 - 120ms/epoch - 3ms/step\nEpoch 8/20\n44/44 - 0s - loss: 1.1337 - sparse_categorical_accuracy: 0.5971 - val_loss: 1.0995 - val_sparse_categorical_accuracy: 0.6156 - 121ms/epoch - 3ms/step\nEpoch 9/20\n44/44 - 0s - loss: 1.1122 - sparse_categorical_accuracy: 0.6121 - val_loss: 1.0771 - val_sparse_categorical_accuracy: 0.6156 - 130ms/epoch - 3ms/step\nEpoch 10/20\n44/44 - 0s - loss: 1.0955 - sparse_categorical_accuracy: 0.6121 - val_loss: 1.0604 - val_sparse_categorical_accuracy: 0.6156 - 127ms/epoch - 3ms/step\nEpoch 11/20\n44/44 - 0s - loss: 1.0826 - sparse_categorical_accuracy: 0.6143 - val_loss: 1.0470 - val_sparse_categorical_accuracy: 0.6190 - 118ms/epoch - 3ms/step\nEpoch 12/20\n44/44 - 0s - loss: 1.0720 - sparse_categorical_accuracy: 0.6157 - val_loss: 1.0360 - val_sparse_categorical_accuracy: 0.6190 - 123ms/epoch - 3ms/step\nEpoch 13/20\n44/44 - 0s - loss: 1.0630 - sparse_categorical_accuracy: 0.6164 - val_loss: 1.0266 - val_sparse_categorical_accuracy: 0.6190 - 127ms/epoch - 3ms/step\nEpoch 14/20\n44/44 - 0s - loss: 1.0552 - sparse_categorical_accuracy: 0.6171 - val_loss: 1.0186 - val_sparse_categorical_accuracy: 0.6190 - 120ms/epoch - 3ms/step\nEpoch 15/20\n44/44 - 0s - loss: 1.0485 - sparse_categorical_accuracy: 0.6171 - val_loss: 1.0117 - val_sparse_categorical_accuracy: 0.6190 - 128ms/epoch - 3ms/step\nEpoch 16/20\n44/44 - 0s - loss: 1.0427 - sparse_categorical_accuracy: 0.6229 - val_loss: 1.0056 - val_sparse_categorical_accuracy: 0.6293 - 151ms/epoch - 3ms/step\nEpoch 17/20\n44/44 - 0s - loss: 1.0376 - sparse_categorical_accuracy: 0.6243 - val_loss: 1.0001 - val_sparse_categorical_accuracy: 0.6293 - 127ms/epoch - 3ms/step\nEpoch 18/20\n44/44 - 0s - loss: 1.0329 - sparse_categorical_accuracy: 0.6250 - val_loss: 0.9952 - val_sparse_categorical_accuracy: 0.6293 - 132ms/epoch - 3ms/step\nEpoch 19/20\n44/44 - 0s - loss: 1.0285 - sparse_categorical_accuracy: 0.6250 - val_loss: 0.9908 - val_sparse_categorical_accuracy: 0.6327 - 119ms/epoch - 3ms/step\nEpoch 20/20\n44/44 - 0s - loss: 1.0247 - sparse_categorical_accuracy: 0.6257 - val_loss: 0.9868 - val_sparse_categorical_accuracy: 0.6327 - 118ms/epoch - 3ms/step\n"}, {"data": {"text/plain": "<keras.callbacks.History at 0x7f1bfd488040>"}, "execution_count": 23, "metadata": {}, "output_type": "execute_result"}], "source": "model_multiclass = keras.Sequential( [keras.layers.Dense(30,activation='relu'),\n                           keras.layers.Dense(6)] )\n\nmodel_multiclass.compile(optimizer = 'sgd',\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=[keras.metrics.SparseCategoricalAccuracy()])\n\nlog_dir = \"logss/multiiclassfin/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n\nmodel_multiclass.fit(x_train,y_train, epochs = 20,validation_data=(x_validate,y_validate),verbose = 2, callbacks=[tensorboard_callback])"}, {"cell_type": "markdown", "id": "36a6ce26", "metadata": {}, "source": "#### Evaluate on Test set"}, {"cell_type": "code", "execution_count": 24, "id": "3a08d705", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Evaluate on test data\n10/10 [==============================] - 0s 2ms/step - loss: 0.9962 - sparse_categorical_accuracy: 0.6340\ntest accuracy =  0.6339869499206543\n"}], "source": "print(\"Evaluate on test data\")\nresults = model_multiclass.evaluate(x_test, y_test)\nprint(\"test accuracy = \", results[1]);"}, {"cell_type": "markdown", "id": "6a53e6f6", "metadata": {}, "source": "### Deep NN"}, {"cell_type": "code", "execution_count": 25, "id": "6528fcd4", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Epoch 1/20\n44/44 - 1s - loss: 1.7333 - sparse_categorical_accuracy: 0.4200 - val_loss: 1.6739 - val_sparse_categorical_accuracy: 0.4490 - 865ms/epoch - 20ms/step\nEpoch 2/20\n44/44 - 0s - loss: 1.5744 - sparse_categorical_accuracy: 0.4871 - val_loss: 1.5574 - val_sparse_categorical_accuracy: 0.4490 - 161ms/epoch - 4ms/step\nEpoch 3/20\n44/44 - 0s - loss: 1.4708 - sparse_categorical_accuracy: 0.4871 - val_loss: 1.4633 - val_sparse_categorical_accuracy: 0.4490 - 158ms/epoch - 4ms/step\nEpoch 4/20\n44/44 - 0s - loss: 1.3934 - sparse_categorical_accuracy: 0.4971 - val_loss: 1.3851 - val_sparse_categorical_accuracy: 0.4762 - 167ms/epoch - 4ms/step\nEpoch 5/20\n44/44 - 0s - loss: 1.3298 - sparse_categorical_accuracy: 0.5186 - val_loss: 1.3115 - val_sparse_categorical_accuracy: 0.5102 - 155ms/epoch - 4ms/step\nEpoch 6/20\n44/44 - 0s - loss: 1.2727 - sparse_categorical_accuracy: 0.5357 - val_loss: 1.2433 - val_sparse_categorical_accuracy: 0.5442 - 161ms/epoch - 4ms/step\nEpoch 7/20\n44/44 - 0s - loss: 1.2217 - sparse_categorical_accuracy: 0.5857 - val_loss: 1.1868 - val_sparse_categorical_accuracy: 0.6088 - 154ms/epoch - 4ms/step\nEpoch 8/20\n44/44 - 0s - loss: 1.1793 - sparse_categorical_accuracy: 0.6021 - val_loss: 1.1395 - val_sparse_categorical_accuracy: 0.6156 - 168ms/epoch - 4ms/step\nEpoch 9/20\n44/44 - 0s - loss: 1.1439 - sparse_categorical_accuracy: 0.6071 - val_loss: 1.1012 - val_sparse_categorical_accuracy: 0.6190 - 154ms/epoch - 4ms/step\nEpoch 10/20\n44/44 - 0s - loss: 1.1154 - sparse_categorical_accuracy: 0.6071 - val_loss: 1.0707 - val_sparse_categorical_accuracy: 0.6259 - 157ms/epoch - 4ms/step\nEpoch 11/20\n44/44 - 0s - loss: 1.0924 - sparse_categorical_accuracy: 0.6171 - val_loss: 1.0461 - val_sparse_categorical_accuracy: 0.6259 - 165ms/epoch - 4ms/step\nEpoch 12/20\n44/44 - 0s - loss: 1.0732 - sparse_categorical_accuracy: 0.6214 - val_loss: 1.0275 - val_sparse_categorical_accuracy: 0.6259 - 160ms/epoch - 4ms/step\nEpoch 13/20\n44/44 - 0s - loss: 1.0580 - sparse_categorical_accuracy: 0.6221 - val_loss: 1.0126 - val_sparse_categorical_accuracy: 0.6259 - 156ms/epoch - 4ms/step\nEpoch 14/20\n44/44 - 0s - loss: 1.0455 - sparse_categorical_accuracy: 0.6250 - val_loss: 1.0003 - val_sparse_categorical_accuracy: 0.6259 - 161ms/epoch - 4ms/step\nEpoch 15/20\n44/44 - 0s - loss: 1.0348 - sparse_categorical_accuracy: 0.6257 - val_loss: 0.9908 - val_sparse_categorical_accuracy: 0.6293 - 161ms/epoch - 4ms/step\nEpoch 16/20\n44/44 - 0s - loss: 1.0260 - sparse_categorical_accuracy: 0.6257 - val_loss: 0.9833 - val_sparse_categorical_accuracy: 0.6293 - 161ms/epoch - 4ms/step\nEpoch 17/20\n44/44 - 0s - loss: 1.0186 - sparse_categorical_accuracy: 0.6257 - val_loss: 0.9763 - val_sparse_categorical_accuracy: 0.6293 - 169ms/epoch - 4ms/step\nEpoch 18/20\n44/44 - 0s - loss: 1.0118 - sparse_categorical_accuracy: 0.6264 - val_loss: 0.9715 - val_sparse_categorical_accuracy: 0.6395 - 154ms/epoch - 3ms/step\nEpoch 19/20\n44/44 - 0s - loss: 1.0062 - sparse_categorical_accuracy: 0.6300 - val_loss: 0.9658 - val_sparse_categorical_accuracy: 0.6395 - 158ms/epoch - 4ms/step\nEpoch 20/20\n44/44 - 0s - loss: 1.0010 - sparse_categorical_accuracy: 0.6350 - val_loss: 0.9611 - val_sparse_categorical_accuracy: 0.6395 - 155ms/epoch - 4ms/step\n"}, {"data": {"text/plain": "<keras.callbacks.History at 0x7f1bfd3a24f0>"}, "execution_count": 25, "metadata": {}, "output_type": "execute_result"}], "source": "import datetime\nmodel_multiclass = keras.Sequential( [keras.layers.Dense(30,activation='relu'),keras.layers.Dense(30,activation='relu'),\n                                      keras.layers.Dense(20,activation='relu'),keras.layers.Dense(20,activation='relu'),\n                           keras.layers.Dense(6)] )\n\nmodel_multiclass.compile(optimizer = 'sgd',\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=[keras.metrics.SparseCategoricalAccuracy()])\n\nlog_dir = \"logss/multiiclassfin/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n\nmodel_multiclass.fit(x_train,y_train, epochs = 20,validation_data=(x_validate,y_validate),verbose = 2, callbacks=[tensorboard_callback])"}, {"cell_type": "markdown", "id": "65ee762f", "metadata": {}, "source": "##### Cross validation function"}, {"cell_type": "code", "execution_count": 26, "id": "346eafea", "metadata": {}, "outputs": [], "source": "def CV_Deep_model(hparams,logdir, k, current_best, d, w):\n    indiceslist = []\n    \n    for i in range(k-1):\n        indices = tf.range(i * ((tf.shape(x_train_shuffle)[0])//k), (i + 1)* ((tf.shape(x_train_shuffle)[0])//k),1).numpy().tolist()\n        indiceslist.append([indices])\n        \n    accuracy = 0\n    # combining whatever remaining after k-1 splits (to account if length of dataset is not divisible by k)\n    \n    indices = tf.range((k-1) * ((tf.shape(x_train_shuffle)[0])//k), (tf.shape(x_train_shuffle)[0]),1).numpy().tolist()\n    \n    indiceslist.append([indices]) ## indiceslist to divide train and validate\n    \n    for i in range(k):\n        print(\"\\nSplit no\",i+1)\n        model = keras.Sequential()\n        for _ in range(hparams[HP_DEPTH]):\n            model.add(keras.layers.Dense(hparams[HP_WIDTH],activation='relu'))\n        model.add(keras.layers.Dense(6))\n        model.compile(\n          optimizer=keras.optimizers.SGD(),\n          loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n          metrics=[keras.metrics.SparseCategoricalAccuracy()])\n        \n        b = indiceslist[i][0] \n        a = [int(item) for item in b]\n\n        x_validate = tf.gather(x_train_shuffle,a)\n\n        y_validate = tf.gather(y_train_shuffle,a)\n        \n        z = []\n        \n        for j in range(k):\n            \n            if j != i:                     ## Make sure validation and train set are different\n                z =  z + indiceslist[j][0]\n                \n        a = [int(item) for item in z]\n        \n        x_train = tf.gather(x_train_shuffle, a)\n        y_train = tf.gather(y_train_shuffle, a)\n        \n        print(\"\\nTraining\")\n        \n        history = model.fit(x_train, y_train, epochs= 10,validation_data = (x_validate,y_validate), verbose = 2)\n        if np.max(history.history[\"val_sparse_categorical_accuracy\"]) > current_best:\n                  current_best = np.max(history.history[\"val_sparse_categorical_accuracy\"])\n                  d = hparams[HP_DEPTH]\n                  w = hparams[HP_WIDTH]\n        accuracy = accuracy + np.max(history.history[\"val_sparse_categorical_accuracy\"])\n    \n    return accuracy/k, d, w, current_best"}, {"cell_type": "markdown", "id": "a524abf5", "metadata": {}, "source": "#### Shuffling"}, {"cell_type": "code", "execution_count": 27, "id": "a2241cba", "metadata": {}, "outputs": [], "source": "train = tf.concat([x_train,tf.reshape(y_train,[-1,1])],1)\ntrain_shuffle = tf.random.shuffle(train)\nx_train_shuffle = train_shuffle[:,0:tf.shape(x_train)[1]]\ny_train_shuffle = train_shuffle[:,tf.shape(x_train)[1]]"}, {"cell_type": "markdown", "id": "cda55e5b", "metadata": {}, "source": "##### Hyperparameters"}, {"cell_type": "code", "execution_count": 28, "id": "7e70baff", "metadata": {}, "outputs": [], "source": "from tensorboard.plugins.hparams import api as hp\n\nHP_WIDTH = hp.HParam('NN_width', hp.Discrete([20,30,40]))\nHP_DEPTH = hp.HParam('NN_depth', hp.Discrete([4,5,6]))\n\n\nwith tf.summary.create_file_writer('logs1483/hparams_tuning').as_default():\n  hp.hparams_config(\n    hparams=[HP_WIDTH, HP_DEPTH],\n    metrics=[hp.Metric('Accuracy')],\n  )"}, {"cell_type": "code", "execution_count": 29, "id": "84395f1b", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "--- Starting trial: run-WIDTH20-DEPTH4\n{'NN_width': 20, 'NN_depth': 4}\n\nSplit no 1\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.8199 - sparse_categorical_accuracy: 0.3019 - val_loss: 1.7505 - val_sparse_categorical_accuracy: 0.4635 - 1s/epoch - 38ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.6743 - sparse_categorical_accuracy: 0.5032 - val_loss: 1.6557 - val_sparse_categorical_accuracy: 0.4227 - 86ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.5750 - sparse_categorical_accuracy: 0.5064 - val_loss: 1.5886 - val_sparse_categorical_accuracy: 0.4227 - 86ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.4981 - sparse_categorical_accuracy: 0.5075 - val_loss: 1.5343 - val_sparse_categorical_accuracy: 0.4292 - 88ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.4324 - sparse_categorical_accuracy: 0.5193 - val_loss: 1.4866 - val_sparse_categorical_accuracy: 0.4421 - 94ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.3765 - sparse_categorical_accuracy: 0.5268 - val_loss: 1.4485 - val_sparse_categorical_accuracy: 0.4421 - 92ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.3314 - sparse_categorical_accuracy: 0.5289 - val_loss: 1.4132 - val_sparse_categorical_accuracy: 0.4506 - 91ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.2943 - sparse_categorical_accuracy: 0.5332 - val_loss: 1.3844 - val_sparse_categorical_accuracy: 0.4592 - 93ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.2641 - sparse_categorical_accuracy: 0.5407 - val_loss: 1.3580 - val_sparse_categorical_accuracy: 0.4635 - 85ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.2388 - sparse_categorical_accuracy: 0.5450 - val_loss: 1.3287 - val_sparse_categorical_accuracy: 0.4742 - 84ms/epoch - 3ms/step\n\nSplit no 2\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.7578 - sparse_categorical_accuracy: 0.4647 - val_loss: 1.7059 - val_sparse_categorical_accuracy: 0.5408 - 784ms/epoch - 26ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.6884 - sparse_categorical_accuracy: 0.4668 - val_loss: 1.6248 - val_sparse_categorical_accuracy: 0.5408 - 85ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.6272 - sparse_categorical_accuracy: 0.4690 - val_loss: 1.5558 - val_sparse_categorical_accuracy: 0.5472 - 85ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.5742 - sparse_categorical_accuracy: 0.4732 - val_loss: 1.4935 - val_sparse_categorical_accuracy: 0.5472 - 98ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.5271 - sparse_categorical_accuracy: 0.4722 - val_loss: 1.4371 - val_sparse_categorical_accuracy: 0.5472 - 86ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.4840 - sparse_categorical_accuracy: 0.4754 - val_loss: 1.3865 - val_sparse_categorical_accuracy: 0.5558 - 89ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.4441 - sparse_categorical_accuracy: 0.4882 - val_loss: 1.3377 - val_sparse_categorical_accuracy: 0.5730 - 92ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.4061 - sparse_categorical_accuracy: 0.5021 - val_loss: 1.2932 - val_sparse_categorical_accuracy: 0.5858 - 87ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.3716 - sparse_categorical_accuracy: 0.5118 - val_loss: 1.2588 - val_sparse_categorical_accuracy: 0.5880 - 86ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.3440 - sparse_categorical_accuracy: 0.5139 - val_loss: 1.2231 - val_sparse_categorical_accuracy: 0.5901 - 92ms/epoch - 3ms/step\n\nSplit no 3\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.7189 - sparse_categorical_accuracy: 0.3830 - val_loss: 1.6598 - val_sparse_categorical_accuracy: 0.5684 - 788ms/epoch - 26ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.6371 - sparse_categorical_accuracy: 0.5773 - val_loss: 1.5804 - val_sparse_categorical_accuracy: 0.5855 - 91ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.5605 - sparse_categorical_accuracy: 0.5783 - val_loss: 1.5062 - val_sparse_categorical_accuracy: 0.5748 - 89ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.4884 - sparse_categorical_accuracy: 0.5708 - val_loss: 1.4368 - val_sparse_categorical_accuracy: 0.5748 - 86ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.4208 - sparse_categorical_accuracy: 0.5708 - val_loss: 1.3746 - val_sparse_categorical_accuracy: 0.5748 - 84ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.3597 - sparse_categorical_accuracy: 0.5773 - val_loss: 1.3213 - val_sparse_categorical_accuracy: 0.5748 - 92ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.3079 - sparse_categorical_accuracy: 0.5794 - val_loss: 1.2789 - val_sparse_categorical_accuracy: 0.5812 - 94ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.2663 - sparse_categorical_accuracy: 0.5805 - val_loss: 1.2448 - val_sparse_categorical_accuracy: 0.5812 - 84ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.2326 - sparse_categorical_accuracy: 0.5848 - val_loss: 1.2195 - val_sparse_categorical_accuracy: 0.5855 - 85ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.2051 - sparse_categorical_accuracy: 0.5912 - val_loss: 1.1983 - val_sparse_categorical_accuracy: 0.5855 - 84ms/epoch - 3ms/step\n--- Starting trial: run-WIDTH20-DEPTH5\n{'NN_width': 20, 'NN_depth': 5}\n\nSplit no 1\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.7644 - sparse_categorical_accuracy: 0.4904 - val_loss: 1.7467 - val_sparse_categorical_accuracy: 0.4227 - 882ms/epoch - 29ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.7022 - sparse_categorical_accuracy: 0.5064 - val_loss: 1.7010 - val_sparse_categorical_accuracy: 0.4270 - 87ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.6449 - sparse_categorical_accuracy: 0.5064 - val_loss: 1.6595 - val_sparse_categorical_accuracy: 0.4270 - 85ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.5933 - sparse_categorical_accuracy: 0.5064 - val_loss: 1.6220 - val_sparse_categorical_accuracy: 0.4270 - 96ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.5453 - sparse_categorical_accuracy: 0.5064 - val_loss: 1.5884 - val_sparse_categorical_accuracy: 0.4270 - 86ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.5014 - sparse_categorical_accuracy: 0.5064 - val_loss: 1.5563 - val_sparse_categorical_accuracy: 0.4270 - 88ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.4588 - sparse_categorical_accuracy: 0.5064 - val_loss: 1.5247 - val_sparse_categorical_accuracy: 0.4270 - 97ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.4168 - sparse_categorical_accuracy: 0.5064 - val_loss: 1.4934 - val_sparse_categorical_accuracy: 0.4270 - 95ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.3793 - sparse_categorical_accuracy: 0.5064 - val_loss: 1.4625 - val_sparse_categorical_accuracy: 0.4270 - 88ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.3431 - sparse_categorical_accuracy: 0.5075 - val_loss: 1.4306 - val_sparse_categorical_accuracy: 0.4292 - 92ms/epoch - 3ms/step\n\nSplit no 2\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.7764 - sparse_categorical_accuracy: 0.3041 - val_loss: 1.7257 - val_sparse_categorical_accuracy: 0.5579 - 849ms/epoch - 28ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.7183 - sparse_categorical_accuracy: 0.4743 - val_loss: 1.6719 - val_sparse_categorical_accuracy: 0.5536 - 88ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.6777 - sparse_categorical_accuracy: 0.4647 - val_loss: 1.6238 - val_sparse_categorical_accuracy: 0.5494 - 85ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.6408 - sparse_categorical_accuracy: 0.4625 - val_loss: 1.5798 - val_sparse_categorical_accuracy: 0.5494 - 86ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.6073 - sparse_categorical_accuracy: 0.4625 - val_loss: 1.5419 - val_sparse_categorical_accuracy: 0.5494 - 85ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.5789 - sparse_categorical_accuracy: 0.4636 - val_loss: 1.5080 - val_sparse_categorical_accuracy: 0.5579 - 93ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.5537 - sparse_categorical_accuracy: 0.4797 - val_loss: 1.4776 - val_sparse_categorical_accuracy: 0.5622 - 86ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.5315 - sparse_categorical_accuracy: 0.4818 - val_loss: 1.4504 - val_sparse_categorical_accuracy: 0.5622 - 89ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.5112 - sparse_categorical_accuracy: 0.4818 - val_loss: 1.4263 - val_sparse_categorical_accuracy: 0.5622 - 88ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.4929 - sparse_categorical_accuracy: 0.4818 - val_loss: 1.4037 - val_sparse_categorical_accuracy: 0.5622 - 86ms/epoch - 3ms/step\n\nSplit no 3\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.7710 - sparse_categorical_accuracy: 0.3519 - val_loss: 1.7339 - val_sparse_categorical_accuracy: 0.4808 - 826ms/epoch - 28ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.7090 - sparse_categorical_accuracy: 0.4968 - val_loss: 1.6814 - val_sparse_categorical_accuracy: 0.4808 - 92ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.6587 - sparse_categorical_accuracy: 0.4968 - val_loss: 1.6356 - val_sparse_categorical_accuracy: 0.4936 - 90ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.6146 - sparse_categorical_accuracy: 0.4968 - val_loss: 1.5909 - val_sparse_categorical_accuracy: 0.4893 - 91ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.5711 - sparse_categorical_accuracy: 0.4903 - val_loss: 1.5514 - val_sparse_categorical_accuracy: 0.4893 - 96ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.5315 - sparse_categorical_accuracy: 0.4903 - val_loss: 1.5138 - val_sparse_categorical_accuracy: 0.4893 - 91ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.4936 - sparse_categorical_accuracy: 0.4903 - val_loss: 1.4782 - val_sparse_categorical_accuracy: 0.4893 - 98ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.4576 - sparse_categorical_accuracy: 0.4796 - val_loss: 1.4438 - val_sparse_categorical_accuracy: 0.4786 - 117ms/epoch - 4ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.4225 - sparse_categorical_accuracy: 0.4785 - val_loss: 1.4125 - val_sparse_categorical_accuracy: 0.4786 - 158ms/epoch - 5ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.3902 - sparse_categorical_accuracy: 0.4861 - val_loss: 1.3825 - val_sparse_categorical_accuracy: 0.4850 - 152ms/epoch - 5ms/step\n--- Starting trial: run-WIDTH20-DEPTH6\n{'NN_width': 20, 'NN_depth': 6}\n\nSplit no 1\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.7263 - sparse_categorical_accuracy: 0.5182 - val_loss: 1.6958 - val_sparse_categorical_accuracy: 0.4227 - 929ms/epoch - 31ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.6251 - sparse_categorical_accuracy: 0.5064 - val_loss: 1.6350 - val_sparse_categorical_accuracy: 0.4227 - 95ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.5496 - sparse_categorical_accuracy: 0.5064 - val_loss: 1.5920 - val_sparse_categorical_accuracy: 0.4270 - 91ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.4922 - sparse_categorical_accuracy: 0.5064 - val_loss: 1.5649 - val_sparse_categorical_accuracy: 0.4270 - 89ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.4530 - sparse_categorical_accuracy: 0.5064 - val_loss: 1.5493 - val_sparse_categorical_accuracy: 0.4270 - 97ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.4246 - sparse_categorical_accuracy: 0.5064 - val_loss: 1.5346 - val_sparse_categorical_accuracy: 0.4270 - 86ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.4012 - sparse_categorical_accuracy: 0.5064 - val_loss: 1.5166 - val_sparse_categorical_accuracy: 0.4270 - 87ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.3783 - sparse_categorical_accuracy: 0.5064 - val_loss: 1.4959 - val_sparse_categorical_accuracy: 0.4270 - 88ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.3558 - sparse_categorical_accuracy: 0.5064 - val_loss: 1.4768 - val_sparse_categorical_accuracy: 0.4270 - 92ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.3314 - sparse_categorical_accuracy: 0.5064 - val_loss: 1.4534 - val_sparse_categorical_accuracy: 0.4227 - 87ms/epoch - 3ms/step\n\nSplit no 2\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.7920 - sparse_categorical_accuracy: 0.1777 - val_loss: 1.7515 - val_sparse_categorical_accuracy: 0.2124 - 911ms/epoch - 30ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.7333 - sparse_categorical_accuracy: 0.3148 - val_loss: 1.6952 - val_sparse_categorical_accuracy: 0.5773 - 91ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.6905 - sparse_categorical_accuracy: 0.5161 - val_loss: 1.6476 - val_sparse_categorical_accuracy: 0.5858 - 91ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.6552 - sparse_categorical_accuracy: 0.5150 - val_loss: 1.6092 - val_sparse_categorical_accuracy: 0.5858 - 87ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.6247 - sparse_categorical_accuracy: 0.5128 - val_loss: 1.5744 - val_sparse_categorical_accuracy: 0.5858 - 94ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.5959 - sparse_categorical_accuracy: 0.5096 - val_loss: 1.5423 - val_sparse_categorical_accuracy: 0.5858 - 90ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.5683 - sparse_categorical_accuracy: 0.5075 - val_loss: 1.5119 - val_sparse_categorical_accuracy: 0.5837 - 91ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.5419 - sparse_categorical_accuracy: 0.5043 - val_loss: 1.4848 - val_sparse_categorical_accuracy: 0.5837 - 89ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.5177 - sparse_categorical_accuracy: 0.5054 - val_loss: 1.4584 - val_sparse_categorical_accuracy: 0.5837 - 98ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.4938 - sparse_categorical_accuracy: 0.5064 - val_loss: 1.4326 - val_sparse_categorical_accuracy: 0.5858 - 88ms/epoch - 3ms/step\n\nSplit no 3\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.7547 - sparse_categorical_accuracy: 0.4667 - val_loss: 1.7089 - val_sparse_categorical_accuracy: 0.5235 - 932ms/epoch - 31ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.6877 - sparse_categorical_accuracy: 0.5139 - val_loss: 1.6470 - val_sparse_categorical_accuracy: 0.5171 - 98ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.6306 - sparse_categorical_accuracy: 0.5129 - val_loss: 1.5977 - val_sparse_categorical_accuracy: 0.4936 - 86ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.5859 - sparse_categorical_accuracy: 0.4796 - val_loss: 1.5554 - val_sparse_categorical_accuracy: 0.4786 - 85ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.5476 - sparse_categorical_accuracy: 0.4807 - val_loss: 1.5229 - val_sparse_categorical_accuracy: 0.4786 - 95ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.5191 - sparse_categorical_accuracy: 0.4807 - val_loss: 1.4996 - val_sparse_categorical_accuracy: 0.4786 - 100ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.4978 - sparse_categorical_accuracy: 0.4807 - val_loss: 1.4796 - val_sparse_categorical_accuracy: 0.4786 - 93ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.4791 - sparse_categorical_accuracy: 0.4882 - val_loss: 1.4611 - val_sparse_categorical_accuracy: 0.4936 - 91ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.4613 - sparse_categorical_accuracy: 0.5129 - val_loss: 1.4424 - val_sparse_categorical_accuracy: 0.5150 - 96ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.4432 - sparse_categorical_accuracy: 0.5150 - val_loss: 1.4248 - val_sparse_categorical_accuracy: 0.5214 - 92ms/epoch - 3ms/step\n--- Starting trial: run-WIDTH30-DEPTH4\n{'NN_width': 30, 'NN_depth': 4}\n\nSplit no 1\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.7003 - sparse_categorical_accuracy: 0.4732 - val_loss: 1.6482 - val_sparse_categorical_accuracy: 0.5086 - 786ms/epoch - 26ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.5578 - sparse_categorical_accuracy: 0.5728 - val_loss: 1.5419 - val_sparse_categorical_accuracy: 0.5043 - 86ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.4343 - sparse_categorical_accuracy: 0.5675 - val_loss: 1.4660 - val_sparse_categorical_accuracy: 0.4936 - 91ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.3467 - sparse_categorical_accuracy: 0.5642 - val_loss: 1.4139 - val_sparse_categorical_accuracy: 0.5000 - 88ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.2873 - sparse_categorical_accuracy: 0.5696 - val_loss: 1.3689 - val_sparse_categorical_accuracy: 0.5150 - 88ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.2447 - sparse_categorical_accuracy: 0.5792 - val_loss: 1.3316 - val_sparse_categorical_accuracy: 0.5193 - 95ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.2095 - sparse_categorical_accuracy: 0.5878 - val_loss: 1.2969 - val_sparse_categorical_accuracy: 0.5300 - 92ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.1815 - sparse_categorical_accuracy: 0.5942 - val_loss: 1.2720 - val_sparse_categorical_accuracy: 0.5343 - 84ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.1593 - sparse_categorical_accuracy: 0.5942 - val_loss: 1.2478 - val_sparse_categorical_accuracy: 0.5472 - 89ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.1423 - sparse_categorical_accuracy: 0.6017 - val_loss: 1.2305 - val_sparse_categorical_accuracy: 0.5494 - 86ms/epoch - 3ms/step\n\nSplit no 2\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.7410 - sparse_categorical_accuracy: 0.4518 - val_loss: 1.7005 - val_sparse_categorical_accuracy: 0.6180 - 1s/epoch - 39ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.6856 - sparse_categorical_accuracy: 0.5525 - val_loss: 1.6416 - val_sparse_categorical_accuracy: 0.6180 - 92ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.6370 - sparse_categorical_accuracy: 0.5493 - val_loss: 1.5871 - val_sparse_categorical_accuracy: 0.6180 - 92ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.5914 - sparse_categorical_accuracy: 0.5364 - val_loss: 1.5360 - val_sparse_categorical_accuracy: 0.6094 - 90ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.5493 - sparse_categorical_accuracy: 0.5343 - val_loss: 1.4863 - val_sparse_categorical_accuracy: 0.6094 - 89ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.5068 - sparse_categorical_accuracy: 0.5332 - val_loss: 1.4389 - val_sparse_categorical_accuracy: 0.6094 - 87ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.4659 - sparse_categorical_accuracy: 0.5353 - val_loss: 1.3927 - val_sparse_categorical_accuracy: 0.6094 - 93ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.4273 - sparse_categorical_accuracy: 0.5289 - val_loss: 1.3496 - val_sparse_categorical_accuracy: 0.5987 - 86ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.3916 - sparse_categorical_accuracy: 0.5246 - val_loss: 1.3111 - val_sparse_categorical_accuracy: 0.5901 - 91ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.3588 - sparse_categorical_accuracy: 0.5278 - val_loss: 1.2743 - val_sparse_categorical_accuracy: 0.6030 - 89ms/epoch - 3ms/step\n\nSplit no 3\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.7532 - sparse_categorical_accuracy: 0.4807 - val_loss: 1.7074 - val_sparse_categorical_accuracy: 0.4786 - 810ms/epoch - 27ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.6724 - sparse_categorical_accuracy: 0.4807 - val_loss: 1.6299 - val_sparse_categorical_accuracy: 0.4786 - 86ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.5993 - sparse_categorical_accuracy: 0.4807 - val_loss: 1.5615 - val_sparse_categorical_accuracy: 0.4786 - 87ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.5359 - sparse_categorical_accuracy: 0.4807 - val_loss: 1.5052 - val_sparse_categorical_accuracy: 0.4786 - 95ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.4842 - sparse_categorical_accuracy: 0.4807 - val_loss: 1.4650 - val_sparse_categorical_accuracy: 0.4786 - 95ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.4448 - sparse_categorical_accuracy: 0.4850 - val_loss: 1.4275 - val_sparse_categorical_accuracy: 0.4829 - 85ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.4074 - sparse_categorical_accuracy: 0.4893 - val_loss: 1.3940 - val_sparse_categorical_accuracy: 0.4829 - 85ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.3719 - sparse_categorical_accuracy: 0.4914 - val_loss: 1.3627 - val_sparse_categorical_accuracy: 0.4915 - 98ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.3366 - sparse_categorical_accuracy: 0.5011 - val_loss: 1.3345 - val_sparse_categorical_accuracy: 0.5000 - 87ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.3039 - sparse_categorical_accuracy: 0.5193 - val_loss: 1.3029 - val_sparse_categorical_accuracy: 0.5171 - 93ms/epoch - 3ms/step\n--- Starting trial: run-WIDTH30-DEPTH5\n{'NN_width': 30, 'NN_depth': 5}\n\nSplit no 1\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.7592 - sparse_categorical_accuracy: 0.4989 - val_loss: 1.7350 - val_sparse_categorical_accuracy: 0.4270 - 884ms/epoch - 29ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.6593 - sparse_categorical_accuracy: 0.5075 - val_loss: 1.6674 - val_sparse_categorical_accuracy: 0.4270 - 87ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.5799 - sparse_categorical_accuracy: 0.5075 - val_loss: 1.6127 - val_sparse_categorical_accuracy: 0.4270 - 89ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.5132 - sparse_categorical_accuracy: 0.5064 - val_loss: 1.5697 - val_sparse_categorical_accuracy: 0.4270 - 94ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.4613 - sparse_categorical_accuracy: 0.5064 - val_loss: 1.5354 - val_sparse_categorical_accuracy: 0.4421 - 88ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.4179 - sparse_categorical_accuracy: 0.5161 - val_loss: 1.5061 - val_sparse_categorical_accuracy: 0.4421 - 89ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.3811 - sparse_categorical_accuracy: 0.5161 - val_loss: 1.4771 - val_sparse_categorical_accuracy: 0.4421 - 94ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.3470 - sparse_categorical_accuracy: 0.5257 - val_loss: 1.4461 - val_sparse_categorical_accuracy: 0.4850 - 87ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.3141 - sparse_categorical_accuracy: 0.5471 - val_loss: 1.4165 - val_sparse_categorical_accuracy: 0.4871 - 89ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.2836 - sparse_categorical_accuracy: 0.5578 - val_loss: 1.3836 - val_sparse_categorical_accuracy: 0.5021 - 94ms/epoch - 3ms/step\n\nSplit no 2\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.7427 - sparse_categorical_accuracy: 0.4411 - val_loss: 1.6997 - val_sparse_categorical_accuracy: 0.5451 - 845ms/epoch - 28ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.6874 - sparse_categorical_accuracy: 0.4540 - val_loss: 1.6348 - val_sparse_categorical_accuracy: 0.5343 - 87ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.6406 - sparse_categorical_accuracy: 0.4529 - val_loss: 1.5758 - val_sparse_categorical_accuracy: 0.5343 - 94ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.5979 - sparse_categorical_accuracy: 0.4529 - val_loss: 1.5248 - val_sparse_categorical_accuracy: 0.5343 - 86ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.5618 - sparse_categorical_accuracy: 0.4529 - val_loss: 1.4800 - val_sparse_categorical_accuracy: 0.5343 - 97ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.5305 - sparse_categorical_accuracy: 0.4529 - val_loss: 1.4398 - val_sparse_categorical_accuracy: 0.5343 - 92ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.5009 - sparse_categorical_accuracy: 0.4529 - val_loss: 1.4040 - val_sparse_categorical_accuracy: 0.5343 - 86ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.4738 - sparse_categorical_accuracy: 0.4529 - val_loss: 1.3682 - val_sparse_categorical_accuracy: 0.5343 - 87ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.4465 - sparse_categorical_accuracy: 0.4529 - val_loss: 1.3349 - val_sparse_categorical_accuracy: 0.5343 - 98ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.4192 - sparse_categorical_accuracy: 0.4540 - val_loss: 1.3090 - val_sparse_categorical_accuracy: 0.5536 - 87ms/epoch - 3ms/step\n\nSplit no 3\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.7083 - sparse_categorical_accuracy: 0.5161 - val_loss: 1.6555 - val_sparse_categorical_accuracy: 0.4957 - 876ms/epoch - 29ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.6298 - sparse_categorical_accuracy: 0.4850 - val_loss: 1.5862 - val_sparse_categorical_accuracy: 0.4829 - 99ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.5595 - sparse_categorical_accuracy: 0.4893 - val_loss: 1.5202 - val_sparse_categorical_accuracy: 0.5021 - 85ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.4962 - sparse_categorical_accuracy: 0.4979 - val_loss: 1.4633 - val_sparse_categorical_accuracy: 0.4829 - 88ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.4424 - sparse_categorical_accuracy: 0.4979 - val_loss: 1.4168 - val_sparse_categorical_accuracy: 0.4829 - 90ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.3972 - sparse_categorical_accuracy: 0.4968 - val_loss: 1.3795 - val_sparse_categorical_accuracy: 0.4829 - 98ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.3598 - sparse_categorical_accuracy: 0.5075 - val_loss: 1.3494 - val_sparse_categorical_accuracy: 0.4829 - 89ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.3286 - sparse_categorical_accuracy: 0.5021 - val_loss: 1.3218 - val_sparse_categorical_accuracy: 0.5085 - 86ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.3010 - sparse_categorical_accuracy: 0.5247 - val_loss: 1.2997 - val_sparse_categorical_accuracy: 0.4979 - 95ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.2763 - sparse_categorical_accuracy: 0.5204 - val_loss: 1.2780 - val_sparse_categorical_accuracy: 0.5214 - 90ms/epoch - 3ms/step\n--- Starting trial: run-WIDTH30-DEPTH6\n{'NN_width': 30, 'NN_depth': 6}\n\nSplit no 1\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.7539 - sparse_categorical_accuracy: 0.4604 - val_loss: 1.7343 - val_sparse_categorical_accuracy: 0.4270 - 930ms/epoch - 31ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.6884 - sparse_categorical_accuracy: 0.5075 - val_loss: 1.6851 - val_sparse_categorical_accuracy: 0.4270 - 101ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.6272 - sparse_categorical_accuracy: 0.5075 - val_loss: 1.6441 - val_sparse_categorical_accuracy: 0.4270 - 88ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.5738 - sparse_categorical_accuracy: 0.5075 - val_loss: 1.6082 - val_sparse_categorical_accuracy: 0.4270 - 91ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.5267 - sparse_categorical_accuracy: 0.5064 - val_loss: 1.5826 - val_sparse_categorical_accuracy: 0.4270 - 99ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.4918 - sparse_categorical_accuracy: 0.5064 - val_loss: 1.5626 - val_sparse_categorical_accuracy: 0.4270 - 89ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.4622 - sparse_categorical_accuracy: 0.5064 - val_loss: 1.5471 - val_sparse_categorical_accuracy: 0.4270 - 87ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.4390 - sparse_categorical_accuracy: 0.5064 - val_loss: 1.5353 - val_sparse_categorical_accuracy: 0.4270 - 87ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.4187 - sparse_categorical_accuracy: 0.5064 - val_loss: 1.5249 - val_sparse_categorical_accuracy: 0.4270 - 93ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.4014 - sparse_categorical_accuracy: 0.5064 - val_loss: 1.5121 - val_sparse_categorical_accuracy: 0.4270 - 89ms/epoch - 3ms/step\n\nSplit no 2\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.7851 - sparse_categorical_accuracy: 0.4015 - val_loss: 1.7223 - val_sparse_categorical_accuracy: 0.5343 - 902ms/epoch - 30ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.7230 - sparse_categorical_accuracy: 0.4529 - val_loss: 1.6583 - val_sparse_categorical_accuracy: 0.5343 - 93ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.6779 - sparse_categorical_accuracy: 0.4529 - val_loss: 1.6051 - val_sparse_categorical_accuracy: 0.5343 - 89ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.6414 - sparse_categorical_accuracy: 0.4529 - val_loss: 1.5614 - val_sparse_categorical_accuracy: 0.5343 - 89ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.6117 - sparse_categorical_accuracy: 0.4529 - val_loss: 1.5243 - val_sparse_categorical_accuracy: 0.5343 - 95ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.5878 - sparse_categorical_accuracy: 0.4529 - val_loss: 1.4932 - val_sparse_categorical_accuracy: 0.5343 - 93ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.5684 - sparse_categorical_accuracy: 0.4529 - val_loss: 1.4695 - val_sparse_categorical_accuracy: 0.5343 - 88ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.5524 - sparse_categorical_accuracy: 0.4529 - val_loss: 1.4496 - val_sparse_categorical_accuracy: 0.5343 - 94ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.5384 - sparse_categorical_accuracy: 0.4529 - val_loss: 1.4261 - val_sparse_categorical_accuracy: 0.5343 - 89ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.5241 - sparse_categorical_accuracy: 0.4529 - val_loss: 1.4094 - val_sparse_categorical_accuracy: 0.5343 - 97ms/epoch - 3ms/step\n\nSplit no 3\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.7532 - sparse_categorical_accuracy: 0.4270 - val_loss: 1.7114 - val_sparse_categorical_accuracy: 0.4786 - 921ms/epoch - 31ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.6797 - sparse_categorical_accuracy: 0.4807 - val_loss: 1.6424 - val_sparse_categorical_accuracy: 0.4786 - 88ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.6146 - sparse_categorical_accuracy: 0.4807 - val_loss: 1.5828 - val_sparse_categorical_accuracy: 0.4786 - 91ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.5584 - sparse_categorical_accuracy: 0.4807 - val_loss: 1.5322 - val_sparse_categorical_accuracy: 0.4786 - 88ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.5126 - sparse_categorical_accuracy: 0.4807 - val_loss: 1.4959 - val_sparse_categorical_accuracy: 0.4786 - 89ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.4763 - sparse_categorical_accuracy: 0.4807 - val_loss: 1.4634 - val_sparse_categorical_accuracy: 0.4786 - 92ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.4458 - sparse_categorical_accuracy: 0.4807 - val_loss: 1.4358 - val_sparse_categorical_accuracy: 0.4786 - 88ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.4169 - sparse_categorical_accuracy: 0.4807 - val_loss: 1.4132 - val_sparse_categorical_accuracy: 0.4786 - 91ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.3923 - sparse_categorical_accuracy: 0.4807 - val_loss: 1.3937 - val_sparse_categorical_accuracy: 0.4786 - 88ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.3712 - sparse_categorical_accuracy: 0.4807 - val_loss: 1.3744 - val_sparse_categorical_accuracy: 0.4786 - 96ms/epoch - 3ms/step\n--- Starting trial: run-WIDTH40-DEPTH4\n{'NN_width': 40, 'NN_depth': 4}\n\nSplit no 1\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.7749 - sparse_categorical_accuracy: 0.4293 - val_loss: 1.7384 - val_sparse_categorical_accuracy: 0.4378 - 794ms/epoch - 26ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.6745 - sparse_categorical_accuracy: 0.5161 - val_loss: 1.6633 - val_sparse_categorical_accuracy: 0.4421 - 85ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.5914 - sparse_categorical_accuracy: 0.5161 - val_loss: 1.6045 - val_sparse_categorical_accuracy: 0.4421 - 89ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.5212 - sparse_categorical_accuracy: 0.5161 - val_loss: 1.5524 - val_sparse_categorical_accuracy: 0.4421 - 88ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.4590 - sparse_categorical_accuracy: 0.5257 - val_loss: 1.5021 - val_sparse_categorical_accuracy: 0.4742 - 88ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.4010 - sparse_categorical_accuracy: 0.5396 - val_loss: 1.4589 - val_sparse_categorical_accuracy: 0.4721 - 94ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.3517 - sparse_categorical_accuracy: 0.5471 - val_loss: 1.4179 - val_sparse_categorical_accuracy: 0.4785 - 88ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.3072 - sparse_categorical_accuracy: 0.5621 - val_loss: 1.3826 - val_sparse_categorical_accuracy: 0.5129 - 88ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.2691 - sparse_categorical_accuracy: 0.5846 - val_loss: 1.3466 - val_sparse_categorical_accuracy: 0.5494 - 92ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.2366 - sparse_categorical_accuracy: 0.5996 - val_loss: 1.3160 - val_sparse_categorical_accuracy: 0.5515 - 87ms/epoch - 3ms/step\n\nSplit no 2\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.7841 - sparse_categorical_accuracy: 0.2388 - val_loss: 1.7301 - val_sparse_categorical_accuracy: 0.2382 - 777ms/epoch - 26ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.6980 - sparse_categorical_accuracy: 0.4347 - val_loss: 1.6490 - val_sparse_categorical_accuracy: 0.5901 - 89ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.6354 - sparse_categorical_accuracy: 0.5193 - val_loss: 1.5808 - val_sparse_categorical_accuracy: 0.5858 - 86ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.5805 - sparse_categorical_accuracy: 0.5161 - val_loss: 1.5204 - val_sparse_categorical_accuracy: 0.5858 - 96ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.5293 - sparse_categorical_accuracy: 0.5182 - val_loss: 1.4605 - val_sparse_categorical_accuracy: 0.5901 - 90ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.4803 - sparse_categorical_accuracy: 0.5214 - val_loss: 1.4085 - val_sparse_categorical_accuracy: 0.5901 - 108ms/epoch - 4ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.4366 - sparse_categorical_accuracy: 0.5203 - val_loss: 1.3567 - val_sparse_categorical_accuracy: 0.5901 - 97ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.3951 - sparse_categorical_accuracy: 0.5193 - val_loss: 1.3112 - val_sparse_categorical_accuracy: 0.5901 - 86ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.3582 - sparse_categorical_accuracy: 0.5182 - val_loss: 1.2682 - val_sparse_categorical_accuracy: 0.5880 - 88ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.3221 - sparse_categorical_accuracy: 0.5450 - val_loss: 1.2279 - val_sparse_categorical_accuracy: 0.6245 - 84ms/epoch - 3ms/step\n\nSplit no 3\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.7783 - sparse_categorical_accuracy: 0.2618 - val_loss: 1.6893 - val_sparse_categorical_accuracy: 0.5769 - 837ms/epoch - 28ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.6532 - sparse_categorical_accuracy: 0.5837 - val_loss: 1.5939 - val_sparse_categorical_accuracy: 0.5791 - 87ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.5594 - sparse_categorical_accuracy: 0.5762 - val_loss: 1.5090 - val_sparse_categorical_accuracy: 0.5705 - 92ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.4739 - sparse_categorical_accuracy: 0.5708 - val_loss: 1.4300 - val_sparse_categorical_accuracy: 0.5641 - 87ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.3947 - sparse_categorical_accuracy: 0.5676 - val_loss: 1.3617 - val_sparse_categorical_accuracy: 0.5620 - 86ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.3280 - sparse_categorical_accuracy: 0.5730 - val_loss: 1.3068 - val_sparse_categorical_accuracy: 0.5641 - 99ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.2744 - sparse_categorical_accuracy: 0.5740 - val_loss: 1.2595 - val_sparse_categorical_accuracy: 0.5705 - 88ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.2283 - sparse_categorical_accuracy: 0.5751 - val_loss: 1.2243 - val_sparse_categorical_accuracy: 0.5705 - 88ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.1919 - sparse_categorical_accuracy: 0.5783 - val_loss: 1.1933 - val_sparse_categorical_accuracy: 0.5769 - 89ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.1614 - sparse_categorical_accuracy: 0.5815 - val_loss: 1.1674 - val_sparse_categorical_accuracy: 0.5812 - 91ms/epoch - 3ms/step\n--- Starting trial: run-WIDTH40-DEPTH5\n{'NN_width': 40, 'NN_depth': 5}\n\nSplit no 1\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.7043 - sparse_categorical_accuracy: 0.5107 - val_loss: 1.6641 - val_sparse_categorical_accuracy: 0.4399 - 1s/epoch - 44ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.5874 - sparse_categorical_accuracy: 0.5268 - val_loss: 1.5894 - val_sparse_categorical_accuracy: 0.4421 - 93ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.4950 - sparse_categorical_accuracy: 0.5257 - val_loss: 1.5266 - val_sparse_categorical_accuracy: 0.4421 - 100ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.4204 - sparse_categorical_accuracy: 0.5278 - val_loss: 1.4817 - val_sparse_categorical_accuracy: 0.4421 - 96ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.3651 - sparse_categorical_accuracy: 0.5289 - val_loss: 1.4470 - val_sparse_categorical_accuracy: 0.4464 - 104ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.3235 - sparse_categorical_accuracy: 0.5310 - val_loss: 1.4148 - val_sparse_categorical_accuracy: 0.4614 - 94ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.2890 - sparse_categorical_accuracy: 0.5396 - val_loss: 1.3858 - val_sparse_categorical_accuracy: 0.4678 - 93ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.2588 - sparse_categorical_accuracy: 0.5471 - val_loss: 1.3539 - val_sparse_categorical_accuracy: 0.4871 - 99ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.2304 - sparse_categorical_accuracy: 0.5589 - val_loss: 1.3282 - val_sparse_categorical_accuracy: 0.4979 - 98ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.2040 - sparse_categorical_accuracy: 0.5653 - val_loss: 1.3014 - val_sparse_categorical_accuracy: 0.5129 - 100ms/epoch - 3ms/step\n\nSplit no 2\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.7637 - sparse_categorical_accuracy: 0.4069 - val_loss: 1.7076 - val_sparse_categorical_accuracy: 0.5429 - 915ms/epoch - 30ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.6954 - sparse_categorical_accuracy: 0.4636 - val_loss: 1.6322 - val_sparse_categorical_accuracy: 0.5429 - 92ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.6316 - sparse_categorical_accuracy: 0.4647 - val_loss: 1.5552 - val_sparse_categorical_accuracy: 0.5429 - 91ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.5742 - sparse_categorical_accuracy: 0.4722 - val_loss: 1.4880 - val_sparse_categorical_accuracy: 0.5708 - 89ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.5237 - sparse_categorical_accuracy: 0.4957 - val_loss: 1.4284 - val_sparse_categorical_accuracy: 0.5815 - 100ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.4781 - sparse_categorical_accuracy: 0.5021 - val_loss: 1.3772 - val_sparse_categorical_accuracy: 0.5923 - 95ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.4356 - sparse_categorical_accuracy: 0.5032 - val_loss: 1.3252 - val_sparse_categorical_accuracy: 0.5944 - 91ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.3939 - sparse_categorical_accuracy: 0.5171 - val_loss: 1.2754 - val_sparse_categorical_accuracy: 0.5901 - 102ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.3535 - sparse_categorical_accuracy: 0.5182 - val_loss: 1.2356 - val_sparse_categorical_accuracy: 0.5901 - 91ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.3197 - sparse_categorical_accuracy: 0.5193 - val_loss: 1.2040 - val_sparse_categorical_accuracy: 0.5901 - 90ms/epoch - 3ms/step\n\nSplit no 3\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.7340 - sparse_categorical_accuracy: 0.4721 - val_loss: 1.6799 - val_sparse_categorical_accuracy: 0.4829 - 861ms/epoch - 29ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.6356 - sparse_categorical_accuracy: 0.4893 - val_loss: 1.5937 - val_sparse_categorical_accuracy: 0.4829 - 99ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.5584 - sparse_categorical_accuracy: 0.4893 - val_loss: 1.5221 - val_sparse_categorical_accuracy: 0.4829 - 91ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.4951 - sparse_categorical_accuracy: 0.4893 - val_loss: 1.4685 - val_sparse_categorical_accuracy: 0.4829 - 90ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.4462 - sparse_categorical_accuracy: 0.4893 - val_loss: 1.4262 - val_sparse_categorical_accuracy: 0.4829 - 97ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.4062 - sparse_categorical_accuracy: 0.5021 - val_loss: 1.3914 - val_sparse_categorical_accuracy: 0.5085 - 95ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.3706 - sparse_categorical_accuracy: 0.5386 - val_loss: 1.3566 - val_sparse_categorical_accuracy: 0.5299 - 91ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.3351 - sparse_categorical_accuracy: 0.5697 - val_loss: 1.3218 - val_sparse_categorical_accuracy: 0.5235 - 99ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.2989 - sparse_categorical_accuracy: 0.5472 - val_loss: 1.2900 - val_sparse_categorical_accuracy: 0.5278 - 90ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.2650 - sparse_categorical_accuracy: 0.5515 - val_loss: 1.2587 - val_sparse_categorical_accuracy: 0.5385 - 90ms/epoch - 3ms/step\n--- Starting trial: run-WIDTH40-DEPTH6\n{'NN_width': 40, 'NN_depth': 6}\n\nSplit no 1\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.7319 - sparse_categorical_accuracy: 0.5268 - val_loss: 1.6989 - val_sparse_categorical_accuracy: 0.4421 - 940ms/epoch - 31ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.6355 - sparse_categorical_accuracy: 0.5182 - val_loss: 1.6345 - val_sparse_categorical_accuracy: 0.4292 - 90ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.5589 - sparse_categorical_accuracy: 0.5075 - val_loss: 1.5842 - val_sparse_categorical_accuracy: 0.4270 - 90ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.4948 - sparse_categorical_accuracy: 0.5064 - val_loss: 1.5475 - val_sparse_categorical_accuracy: 0.4270 - 98ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.4454 - sparse_categorical_accuracy: 0.5086 - val_loss: 1.5203 - val_sparse_categorical_accuracy: 0.4313 - 91ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.4056 - sparse_categorical_accuracy: 0.5182 - val_loss: 1.4913 - val_sparse_categorical_accuracy: 0.4421 - 99ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.3719 - sparse_categorical_accuracy: 0.5257 - val_loss: 1.4631 - val_sparse_categorical_accuracy: 0.4485 - 90ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.3387 - sparse_categorical_accuracy: 0.5321 - val_loss: 1.4354 - val_sparse_categorical_accuracy: 0.4571 - 92ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.3041 - sparse_categorical_accuracy: 0.5364 - val_loss: 1.4003 - val_sparse_categorical_accuracy: 0.4785 - 99ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.2695 - sparse_categorical_accuracy: 0.5482 - val_loss: 1.3690 - val_sparse_categorical_accuracy: 0.4828 - 99ms/epoch - 3ms/step\n\nSplit no 2\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.7557 - sparse_categorical_accuracy: 0.4561 - val_loss: 1.6970 - val_sparse_categorical_accuracy: 0.5343 - 928ms/epoch - 31ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.6824 - sparse_categorical_accuracy: 0.4529 - val_loss: 1.6160 - val_sparse_categorical_accuracy: 0.5343 - 93ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.6214 - sparse_categorical_accuracy: 0.4529 - val_loss: 1.5468 - val_sparse_categorical_accuracy: 0.5343 - 90ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.5723 - sparse_categorical_accuracy: 0.4529 - val_loss: 1.4825 - val_sparse_categorical_accuracy: 0.5343 - 95ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.5273 - sparse_categorical_accuracy: 0.4529 - val_loss: 1.4321 - val_sparse_categorical_accuracy: 0.5343 - 90ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.4922 - sparse_categorical_accuracy: 0.4529 - val_loss: 1.3894 - val_sparse_categorical_accuracy: 0.5343 - 92ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.4603 - sparse_categorical_accuracy: 0.4529 - val_loss: 1.3546 - val_sparse_categorical_accuracy: 0.5343 - 105ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.4308 - sparse_categorical_accuracy: 0.4529 - val_loss: 1.3198 - val_sparse_categorical_accuracy: 0.5343 - 90ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.4009 - sparse_categorical_accuracy: 0.4668 - val_loss: 1.2877 - val_sparse_categorical_accuracy: 0.5536 - 91ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.3695 - sparse_categorical_accuracy: 0.4818 - val_loss: 1.2551 - val_sparse_categorical_accuracy: 0.5794 - 95ms/epoch - 3ms/step\n\nSplit no 3\n\nTraining\nEpoch 1/10\n30/30 - 1s - loss: 1.7613 - sparse_categorical_accuracy: 0.4517 - val_loss: 1.7158 - val_sparse_categorical_accuracy: 0.4786 - 927ms/epoch - 31ms/step\nEpoch 2/10\n30/30 - 0s - loss: 1.6819 - sparse_categorical_accuracy: 0.4807 - val_loss: 1.6484 - val_sparse_categorical_accuracy: 0.4786 - 91ms/epoch - 3ms/step\nEpoch 3/10\n30/30 - 0s - loss: 1.6174 - sparse_categorical_accuracy: 0.4807 - val_loss: 1.5843 - val_sparse_categorical_accuracy: 0.4786 - 90ms/epoch - 3ms/step\nEpoch 4/10\n30/30 - 0s - loss: 1.5570 - sparse_categorical_accuracy: 0.4807 - val_loss: 1.5245 - val_sparse_categorical_accuracy: 0.4786 - 92ms/epoch - 3ms/step\nEpoch 5/10\n30/30 - 0s - loss: 1.5016 - sparse_categorical_accuracy: 0.4807 - val_loss: 1.4776 - val_sparse_categorical_accuracy: 0.4786 - 99ms/epoch - 3ms/step\nEpoch 6/10\n30/30 - 0s - loss: 1.4560 - sparse_categorical_accuracy: 0.4807 - val_loss: 1.4316 - val_sparse_categorical_accuracy: 0.4786 - 94ms/epoch - 3ms/step\nEpoch 7/10\n30/30 - 0s - loss: 1.4118 - sparse_categorical_accuracy: 0.5043 - val_loss: 1.3904 - val_sparse_categorical_accuracy: 0.5235 - 91ms/epoch - 3ms/step\nEpoch 8/10\n30/30 - 0s - loss: 1.3703 - sparse_categorical_accuracy: 0.5172 - val_loss: 1.3468 - val_sparse_categorical_accuracy: 0.5235 - 93ms/epoch - 3ms/step\nEpoch 9/10\n30/30 - 0s - loss: 1.3298 - sparse_categorical_accuracy: 0.5193 - val_loss: 1.3055 - val_sparse_categorical_accuracy: 0.5321 - 90ms/epoch - 3ms/step\nEpoch 10/10\n30/30 - 0s - loss: 1.2894 - sparse_categorical_accuracy: 0.5258 - val_loss: 1.2693 - val_sparse_categorical_accuracy: 0.5491 - 89ms/epoch - 3ms/step\n"}], "source": "k =3 \ncurrent_best = 0\nd,w = 0,0\nfor hp_width in HP_WIDTH.domain.values:\n  for hp_depth in (HP_DEPTH.domain.values):\n    hparams = {\n        HP_WIDTH: hp_width,\n        HP_DEPTH: hp_depth,\n    }\n    run_name = f\"run-WIDTH{int(hparams[HP_WIDTH])}-DEPTH{hparams[HP_DEPTH]}\"\n    print('--- Starting trial: %s' % run_name)\n    print({h.name: hparams[h] for h in hparams})\n\n    run_dir = 'logs1483/hparams_tuning/' + run_name\n    accuracy, d, w, current_best = CV_Deep_model(hparams,run_dir, k, current_best, d, w)\n\n    with tf.summary.create_file_writer(run_dir).as_default():\n      hp.hparams(hparams)  # record the values used in this trial\n      tf.summary.scalar(\"Accuracy\", accuracy, step=1)"}, {"cell_type": "markdown", "id": "6d26f877", "metadata": {}, "source": "### Best Parameters"}, {"cell_type": "code", "execution_count": 30, "id": "02f3d3ed", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Tuned Depth for Deep NN =  4\nTuned Widhth for Deep NN =  40\n"}], "source": "print(\"Tuned Depth for Deep NN = \",d)\nprint(\"Tuned Widhth for Deep NN = \",w)"}, {"cell_type": "code", "execution_count": 31, "id": "fe2b6bd0", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Epoch 1/20\n44/44 - 1s - loss: 1.7127 - sparse_categorical_accuracy: 0.4179 - val_loss: 1.6267 - val_sparse_categorical_accuracy: 0.5646 - 840ms/epoch - 19ms/step\nEpoch 2/20\n44/44 - 0s - loss: 1.5698 - sparse_categorical_accuracy: 0.5671 - val_loss: 1.5112 - val_sparse_categorical_accuracy: 0.5442 - 173ms/epoch - 4ms/step\nEpoch 3/20\n44/44 - 0s - loss: 1.4564 - sparse_categorical_accuracy: 0.5586 - val_loss: 1.4047 - val_sparse_categorical_accuracy: 0.5442 - 158ms/epoch - 4ms/step\nEpoch 4/20\n44/44 - 0s - loss: 1.3556 - sparse_categorical_accuracy: 0.5764 - val_loss: 1.3061 - val_sparse_categorical_accuracy: 0.5748 - 168ms/epoch - 4ms/step\nEpoch 5/20\n44/44 - 0s - loss: 1.2702 - sparse_categorical_accuracy: 0.5929 - val_loss: 1.2257 - val_sparse_categorical_accuracy: 0.5986 - 158ms/epoch - 4ms/step\nEpoch 6/20\n44/44 - 0s - loss: 1.2073 - sparse_categorical_accuracy: 0.6050 - val_loss: 1.1693 - val_sparse_categorical_accuracy: 0.6088 - 160ms/epoch - 4ms/step\nEpoch 7/20\n44/44 - 0s - loss: 1.1625 - sparse_categorical_accuracy: 0.6121 - val_loss: 1.1266 - val_sparse_categorical_accuracy: 0.6088 - 164ms/epoch - 4ms/step\nEpoch 8/20\n44/44 - 0s - loss: 1.1293 - sparse_categorical_accuracy: 0.6143 - val_loss: 1.0951 - val_sparse_categorical_accuracy: 0.6088 - 156ms/epoch - 4ms/step\nEpoch 9/20\n44/44 - 0s - loss: 1.1041 - sparse_categorical_accuracy: 0.6150 - val_loss: 1.0702 - val_sparse_categorical_accuracy: 0.6088 - 160ms/epoch - 4ms/step\nEpoch 10/20\n44/44 - 0s - loss: 1.0839 - sparse_categorical_accuracy: 0.6150 - val_loss: 1.0497 - val_sparse_categorical_accuracy: 0.6088 - 163ms/epoch - 4ms/step\nEpoch 11/20\n44/44 - 0s - loss: 1.0673 - sparse_categorical_accuracy: 0.6171 - val_loss: 1.0323 - val_sparse_categorical_accuracy: 0.6088 - 173ms/epoch - 4ms/step\nEpoch 12/20\n44/44 - 0s - loss: 1.0534 - sparse_categorical_accuracy: 0.6179 - val_loss: 1.0176 - val_sparse_categorical_accuracy: 0.6224 - 162ms/epoch - 4ms/step\nEpoch 13/20\n44/44 - 0s - loss: 1.0416 - sparse_categorical_accuracy: 0.6257 - val_loss: 1.0054 - val_sparse_categorical_accuracy: 0.6259 - 168ms/epoch - 4ms/step\nEpoch 14/20\n44/44 - 0s - loss: 1.0316 - sparse_categorical_accuracy: 0.6264 - val_loss: 0.9960 - val_sparse_categorical_accuracy: 0.6259 - 160ms/epoch - 4ms/step\nEpoch 15/20\n44/44 - 0s - loss: 1.0234 - sparse_categorical_accuracy: 0.6279 - val_loss: 0.9876 - val_sparse_categorical_accuracy: 0.6293 - 170ms/epoch - 4ms/step\nEpoch 16/20\n44/44 - 0s - loss: 1.0162 - sparse_categorical_accuracy: 0.6279 - val_loss: 0.9805 - val_sparse_categorical_accuracy: 0.6293 - 170ms/epoch - 4ms/step\nEpoch 17/20\n44/44 - 0s - loss: 1.0095 - sparse_categorical_accuracy: 0.6279 - val_loss: 0.9745 - val_sparse_categorical_accuracy: 0.6293 - 170ms/epoch - 4ms/step\nEpoch 18/20\n44/44 - 0s - loss: 1.0040 - sparse_categorical_accuracy: 0.6286 - val_loss: 0.9702 - val_sparse_categorical_accuracy: 0.6293 - 186ms/epoch - 4ms/step\nEpoch 19/20\n44/44 - 0s - loss: 0.9990 - sparse_categorical_accuracy: 0.6293 - val_loss: 0.9652 - val_sparse_categorical_accuracy: 0.6293 - 168ms/epoch - 4ms/step\nEpoch 20/20\n44/44 - 0s - loss: 0.9948 - sparse_categorical_accuracy: 0.6321 - val_loss: 0.9612 - val_sparse_categorical_accuracy: 0.6395 - 172ms/epoch - 4ms/step\n"}, {"data": {"text/plain": "<keras.callbacks.History at 0x7f1bfd814b50>"}, "execution_count": 31, "metadata": {}, "output_type": "execute_result"}], "source": "model_multiclass = keras.Sequential( [keras.layers.Dense(40,activation='relu'),keras.layers.Dense(40,activation='relu'),\n                           keras.layers.Dense(40,activation='relu'), keras.layers.Dense(40,activation='relu'),\n                           keras.layers.Dense(6)] )\n\nmodel_multiclass.compile(optimizer = 'sgd',\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=[keras.metrics.SparseCategoricalAccuracy()])\n\nlog_dir = \"logss/multiiclassfin/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n\nmodel_multiclass.fit(x_train,y_train, epochs = 20,validation_data=(x_validate,y_validate),verbose = 2, callbacks=[tensorboard_callback])"}, {"cell_type": "markdown", "id": "e073eda7", "metadata": {}, "source": "### Testing on Test set"}, {"cell_type": "code", "execution_count": 32, "id": "ed201c02", "metadata": {"scrolled": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Evaluate on test data\n10/10 [==============================] - 0s 2ms/step - loss: 0.9744 - sparse_categorical_accuracy: 0.6405\ntest accuracy =  0.6405228972434998\n"}], "source": "print(\"Evaluate on test data\")\nresults = model_multiclass.evaluate(x_test, y_test)\nprint(\"test accuracy = \", results[1]);"}, {"cell_type": "markdown", "id": "e00081df", "metadata": {}, "source": "## Binary Classification"}, {"cell_type": "code", "execution_count": 33, "id": "1b65ccc5", "metadata": {}, "outputs": [{"ename": "AnalysisException", "evalue": "Path does not exist: gs://dataproc-staging-us-west3-650974721448-vbkdchoj/test30_augmented.csv", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)", "Cell \u001b[0;32mIn [33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgs://dataproc-staging-us-west3-650974721448-vbkdchoj/test30_augmented.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minferSchema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m train \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mcsv( (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgs://dataproc-staging-us-west3-650974721448-vbkdchoj/train70_augmented.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m),header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inferSchema\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m DF \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39munion(test)\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/sql/readwriter.py:737\u001b[0m, in \u001b[0;36mDataFrameReader.csv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[1;32m    735\u001b[0m     path \u001b[38;5;241m=\u001b[39m [path]\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(path) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m--> 737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoSeq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, RDD):\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(iterator):\n", "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/py4j/java_gateway.py:1304\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1308\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n", "\u001b[0;31mAnalysisException\u001b[0m: Path does not exist: gs://dataproc-staging-us-west3-650974721448-vbkdchoj/test30_augmented.csv"]}], "source": "test = spark.read.csv( (\"gs://dataproc-staging-us-west3-650974721448-vbkdchoj/test30_augmented.csv\"),header=True, inferSchema= True)\ntrain = spark.read.csv( (\"gs://dataproc-staging-us-west3-650974721448-vbkdchoj/train70_augmented.csv\"),header=True, inferSchema= True)\nDF = train.union(test)\nDF = DF.toDF(*(c.replace('.', '_') for c in DF.columns))\ntrain = train.toDF(*(c.replace('.', '_') for c in train.columns))\ntest = test.toDF(*(c.replace('.', '_') for c in test.columns))\ntrain = train.drop(\"mqtt_hdrflags\", \"tcp_flags\", 'mqtt_conack_flags','mqtt_conflags','mqtt_msg',\n        'mqtt_protoname')\ntest = test.drop(\"mqtt_hdrflags\", \"tcp_flags\", 'mqtt_conack_flags','mqtt_conflags','mqtt_msg',\n        'mqtt_protoname')\ntrain = train.limit(1400)\ntest = test.limit(600)"}, {"cell_type": "code", "execution_count": null, "id": "2c09e4af", "metadata": {}, "outputs": [], "source": "preprocess_pipeline = get_preprocess_pipeline(\"binary\")\npreprocess_pipeline_model = preprocess_pipeline.fit(train)\n\ntrain_df = preprocess_pipeline_model.transform(train)\ntest_df = preprocess_pipeline_model.transform(test)"}, {"cell_type": "code", "execution_count": null, "id": "b56c60ed", "metadata": {}, "outputs": [], "source": "to_array = udf(lambda v: v.toArray().tolist(), ArrayType(FloatType()))\n\ndf_train = train_df\ndf_validate,df_test = test_df.randomSplit([0.5,0.5])"}, {"cell_type": "code", "execution_count": null, "id": "04839210", "metadata": {}, "outputs": [], "source": "df_train_pandas = df_train.withColumn('features', to_array('features')).toPandas()\ndf_validate_pandas = df_validate.withColumn('features', to_array('features')).toPandas()\ndf_test_pandas = df_test.withColumn('features', to_array('features')).toPandas()"}, {"cell_type": "code", "execution_count": null, "id": "42a4a44c", "metadata": {}, "outputs": [], "source": "import tensorflow as tf\nfrom tensorflow import keras \n\n# Converting the pandas DataFrame to tensors\n# Note we are using 3 data sets train, validate, test\n\nx_train = tf.constant(np.array(df_train_pandas['features'].values.tolist()))\ny_train = tf.constant(np.array(df_train_pandas['outcome'].values.tolist()))\n\nx_validate = tf.constant(np.array(df_validate_pandas['features'].values.tolist()))\ny_validate = tf.constant(np.array(df_validate_pandas['outcome'].values.tolist()))\n\n\nx_test = tf.constant(np.array(df_test_pandas['features'].values.tolist()))\ny_test = tf.constant(np.array(df_test_pandas['outcome'].values.tolist()))"}, {"cell_type": "markdown", "id": "810a69b8", "metadata": {}, "source": "#### Shallow NN"}, {"cell_type": "code", "execution_count": null, "id": "6dd8815c", "metadata": {}, "outputs": [], "source": "import datetime\nmodel = keras.Sequential( [keras.layers.Dense(30,activation='relu'),\n                           keras.layers.Dense(1)] )\nmodel.compile(optimizer = 'sgd',\n    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n    metrics=[keras.metrics.AUC(from_logits=True),keras.metrics.BinaryAccuracy()])\n\nmodel.fit(x_train,y_train, epochs = 10,validation_data=(x_validate,y_validate),verbose = 2)"}, {"cell_type": "markdown", "id": "027e20d3", "metadata": {}, "source": "#### Shuffling"}, {"cell_type": "code", "execution_count": null, "id": "68a22f66", "metadata": {}, "outputs": [], "source": "import tensorflow as tf\nfrom tensorflow import keras \ntrain = tf.concat([x_train,tf.reshape(y_train,[-1,1])],1)\ntrain_shuffle = tf.random.shuffle(train)\nx_train_shuffle = train_shuffle[:,0:tf.shape(x_train)[1]]\ny_train_shuffle = train_shuffle[:,tf.shape(x_train)[1]]"}, {"cell_type": "markdown", "id": "5d4b5f25", "metadata": {}, "source": "#### Hyperparameters"}, {"cell_type": "code", "execution_count": null, "id": "acbc56ff", "metadata": {}, "outputs": [], "source": "from tensorboard.plugins.hparams import api as hp\n\nHP_WIDTH = hp.HParam('NN_width', hp.Discrete([20,30,40]))\nHP_DEPTH = hp.HParam('NN_depth', hp.Discrete([1,2]))\n\n\nwith tf.summary.create_file_writer('logs1483/hparams_tuning').as_default():\n  hp.hparams_config(\n    hparams=[HP_WIDTH, HP_DEPTH],\n    metrics=[hp.Metric('Accuracy')],\n  )"}, {"cell_type": "markdown", "id": "ff552177", "metadata": {}, "source": "#### Cross Validation"}, {"cell_type": "code", "execution_count": null, "id": "d4a64dd8", "metadata": {}, "outputs": [], "source": "def CV_Binary_model(hparams,logdir, k, current_best, d, w):\n    indiceslist = []\n    \n    for i in range(k-1):\n        indices = tf.range(i * ((tf.shape(x_train_shuffle)[0])//k), (i + 1)* ((tf.shape(x_train_shuffle)[0])//k),1).numpy().tolist()\n        indiceslist.append([indices])\n        \n    accuracy = 0\n    # combining whatever remaining after k-1 splits (to account if length of dataset is not divisible by k)\n    \n    indices = tf.range((k-1) * ((tf.shape(x_train_shuffle)[0])//k), (tf.shape(x_train_shuffle)[0]),1).numpy().tolist()\n    \n    indiceslist.append([indices]) ## indiceslist to divide train and validate\n    \n    for i in range(k):\n        print(\"\\nSplit no\",i+1)\n        model = keras.Sequential()\n        for _ in range(hparams[HP_DEPTH]):\n            model.add(keras.layers.Dense(hparams[HP_WIDTH],activation='relu'))\n        model.add(keras.layers.Dense(1))\n        model.compile(optimizer = 'sgd',\n        loss=keras.losses.BinaryCrossentropy(from_logits=True),\n        metrics=[keras.metrics.AUC(from_logits=True),keras.metrics.BinaryAccuracy()])\n        \n        b = indiceslist[i][0] \n        a = [int(item) for item in b]\n\n        x_validate = tf.gather(x_train_shuffle,a)\n\n        y_validate = tf.gather(y_train_shuffle,a)\n        \n        z = []\n        \n        for j in range(k):\n            \n            if j != i:                     ## Make sure validation and train set are different\n                z =  z + indiceslist[j][0]\n                \n        a = [int(item) for item in z]\n        \n        x_train = tf.gather(x_train_shuffle, a)\n        y_train = tf.gather(y_train_shuffle, a)\n        \n        print(\"\\nTraining\")\n        \n        history = model.fit(x_train, y_train, epochs= 10,validation_data = (x_validate,y_validate), verbose = 2)\n        if np.max(history.history[\"val_binary_accuracy\"]) > current_best:\n                  current_best = np.max(history.history[\"val_binary_accuracy\"])\n                  d = hparams[HP_DEPTH]\n                  w = hparams[HP_WIDTH]\n        accuracy = accuracy + np.max(history.history[\"val_binary_accuracy\"])\n    \n    return accuracy/k, d, w, current_best"}, {"cell_type": "markdown", "id": "78f157ac", "metadata": {}, "source": "#### Tuning"}, {"cell_type": "code", "execution_count": null, "id": "2d31082d", "metadata": {}, "outputs": [], "source": "k =3 \ncurrent_best = 0\nd,w = 0,0\nfor hp_width in HP_WIDTH.domain.values:\n  for hp_depth in (HP_DEPTH.domain.values):\n    hparams = {\n        HP_WIDTH: hp_width,\n        HP_DEPTH: hp_depth,\n    }\n    run_name = f\"run-WIDTH{int(hparams[HP_WIDTH])}-DEPTH{hparams[HP_DEPTH]}\"\n    print('--- Starting trial: %s' % run_name)\n    print({h.name: hparams[h] for h in hparams})\n\n    run_dir = 'logs1483/hparams_tuning/' + run_name\n    accuracy, d, w, current_best = CV_Binary_model(hparams,run_dir, k, current_best, d, w)\n\n    with tf.summary.create_file_writer(run_dir).as_default():\n      hp.hparams(hparams)  # record the values used in this trial\n      tf.summary.scalar(\"Accuracy\", accuracy, step=1)"}, {"cell_type": "markdown", "id": "258e418b", "metadata": {}, "source": "#### Best parameters"}, {"cell_type": "code", "execution_count": null, "id": "8478278c", "metadata": {}, "outputs": [], "source": "print(\"Tuned Depth for Shallow NN = \",d)\nprint(\"Tuned Widhth for Shallow NN = \",w)"}, {"cell_type": "code", "execution_count": null, "id": "b0c9ee77", "metadata": {}, "outputs": [], "source": "model = keras.Sequential( [keras.layers.Dense(40,activation='relu'),\n                           keras.layers.Dense(1)] )\n\nmodel.compile(optimizer = 'sgd',\n    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n    metrics=[keras.metrics.AUC(from_logits=True),keras.metrics.BinaryAccuracy()])\n\nmodel.fit(x_train,y_train, epochs = 20,validation_data=(x_validate,y_validate),verbose = 2)"}, {"cell_type": "markdown", "id": "d56bed77", "metadata": {}, "source": "#### Testing on Test set"}, {"cell_type": "code", "execution_count": null, "id": "1da65d22", "metadata": {}, "outputs": [], "source": "print(\"Evaluate on test data\")\nresults = model.evaluate(x_test, y_test)\nprint(\"test accuracy = \", results[2]);"}, {"cell_type": "markdown", "id": "db9e95fd", "metadata": {}, "source": "#### Deep NN"}, {"cell_type": "code", "execution_count": null, "id": "aa79cce3", "metadata": {}, "outputs": [], "source": "import datetime\nmodel = keras.Sequential( [keras.layers.Dense(30,activation='relu'),keras.layers.Dense(30,activation='relu'),\n                           keras.layers.Dense(30,activation='relu'),keras.layers.Dense(30,activation='relu'),\n                           keras.layers.Dense(1)] )\nmodel.compile(optimizer = 'sgd',\n    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n    metrics=[keras.metrics.AUC(from_logits=True),keras.metrics.BinaryAccuracy()])\n\nmodel.fit(x_train,y_train, epochs = 10,validation_data=(x_validate,y_validate),verbose = 2)"}, {"cell_type": "markdown", "id": "cb0e1d7a", "metadata": {}, "source": "#### Shuffling"}, {"cell_type": "code", "execution_count": null, "id": "0856c160", "metadata": {}, "outputs": [], "source": "import tensorflow as tf\nfrom tensorflow import keras \ntrain = tf.concat([x_train,tf.reshape(y_train,[-1,1])],1)\ntrain_shuffle = tf.random.shuffle(train)\nx_train_shuffle = train_shuffle[:,0:tf.shape(x_train)[1]]\ny_train_shuffle = train_shuffle[:,tf.shape(x_train)[1]]"}, {"cell_type": "markdown", "id": "e0ea11d9", "metadata": {}, "source": "#### Hyper parameters"}, {"cell_type": "code", "execution_count": null, "id": "e86811e5", "metadata": {}, "outputs": [], "source": "from tensorboard.plugins.hparams import api as hp\n\nHP_WIDTH = hp.HParam('NN_width', hp.Discrete([20,30,40]))\nHP_DEPTH = hp.HParam('NN_depth', hp.Discrete([4,5,6]))\n\n\nwith tf.summary.create_file_writer('logs1483/hparams_tuning').as_default():\n  hp.hparams_config(\n    hparams=[HP_WIDTH, HP_DEPTH],\n    metrics=[hp.Metric('Accuracy')],\n  )"}, {"cell_type": "markdown", "id": "203b2256", "metadata": {}, "source": "#### CrossValidation"}, {"cell_type": "code", "execution_count": null, "id": "8c43f27d", "metadata": {}, "outputs": [], "source": "def CV_Deep_Binary_model(hparams,logdir, k, current_best, d, w):\n    indiceslist = []\n    \n    for i in range(k-1):\n        indices = tf.range(i * ((tf.shape(x_train_shuffle)[0])//k), (i + 1)* ((tf.shape(x_train_shuffle)[0])//k),1).numpy().tolist()\n        indiceslist.append([indices])\n        \n    accuracy = 0\n    # combining whatever remaining after k-1 splits (to account if length of dataset is not divisible by k)\n    \n    indices = tf.range((k-1) * ((tf.shape(x_train_shuffle)[0])//k), (tf.shape(x_train_shuffle)[0]),1).numpy().tolist()\n    \n    indiceslist.append([indices]) ## indiceslist to divide train and validate\n    \n    for i in range(k):\n        print(\"\\nSplit no\",i+1)\n        model = keras.Sequential()\n        for _ in range(hparams[HP_DEPTH]):\n            model.add(keras.layers.Dense(hparams[HP_WIDTH],activation='relu'))\n        model.add(keras.layers.Dense(1))\n        model.compile(optimizer = 'sgd',\n        loss=keras.losses.BinaryCrossentropy(from_logits=True),\n        metrics=[keras.metrics.AUC(from_logits=True),keras.metrics.BinaryAccuracy()])\n        \n        b = indiceslist[i][0] \n        a = [int(item) for item in b]\n\n        x_validate = tf.gather(x_train_shuffle,a)\n\n        y_validate = tf.gather(y_train_shuffle,a)\n        \n        z = []\n        \n        for j in range(k):\n            \n            if j != i:                     ## Make sure validation and train set are different\n                z =  z + indiceslist[j][0]\n                \n        a = [int(item) for item in z]\n        \n        x_train = tf.gather(x_train_shuffle, a)\n        y_train = tf.gather(y_train_shuffle, a)\n        \n        print(\"\\nTraining\")\n        \n        history = model.fit(x_train, y_train, epochs= 10,validation_data = (x_validate,y_validate), verbose = 2)\n        if np.max(history.history[\"val_binary_accuracy\"]) > current_best:\n                  current_best = np.max(history.history[\"val_binary_accuracy\"])\n                  d = hparams[HP_DEPTH]\n                  w = hparams[HP_WIDTH]\n        accuracy = accuracy + np.max(history.history[\"val_binary_accuracy\"])\n    \n    return accuracy/k, d, w, current_best"}, {"cell_type": "markdown", "id": "daae3b17", "metadata": {}, "source": "#### Tuning"}, {"cell_type": "code", "execution_count": null, "id": "193031a6", "metadata": {}, "outputs": [], "source": "k =3 \ncurrent_best = 0\nd,w = 0,0\nfor hp_width in HP_WIDTH.domain.values:\n  for hp_depth in (HP_DEPTH.domain.values):\n    hparams = {\n        HP_WIDTH: hp_width,\n        HP_DEPTH: hp_depth,\n    }\n    run_name = f\"run-WIDTH{int(hparams[HP_WIDTH])}-DEPTH{hparams[HP_DEPTH]}\"\n    print('--- Starting trial: %s' % run_name)\n    print({h.name: hparams[h] for h in hparams})\n\n    run_dir = 'logs1483/hparams_tuning/' + run_name\n    accuracy, d, w, current_best = CV_Deep_Binary_model(hparams,run_dir, k, current_best, d, w)\n\n    with tf.summary.create_file_writer(run_dir).as_default():\n      hp.hparams(hparams)  # record the values used in this trial\n      tf.summary.scalar(\"Accuracy\", accuracy, step=1)"}, {"cell_type": "markdown", "id": "a092955e", "metadata": {}, "source": "#### Tuned Parameters"}, {"cell_type": "code", "execution_count": null, "id": "1bce1e76", "metadata": {}, "outputs": [], "source": "print(\"Tuned Depth for Deep NN = \",d)\nprint(\"Tuned Widhth for Deep NN = \",w)"}, {"cell_type": "code", "execution_count": null, "id": "7bced657", "metadata": {}, "outputs": [], "source": "model = keras.Sequential( [keras.layers.Dense(40,activation='relu'),keras.layers.Dense(40,activation='relu'),\n                           keras.layers.Dense(40,activation='relu'),keras.layers.Dense(40,activation='relu'),\n                           keras.layers.Dense(1)] )\n\nmodel.compile(optimizer = 'sgd',\n    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n    metrics=[keras.metrics.AUC(from_logits=True),keras.metrics.BinaryAccuracy()])\n\nmodel.fit(x_train,y_train, epochs = 20,validation_data=(x_validate,y_validate),verbose = 2)"}, {"cell_type": "markdown", "id": "6eef04fd", "metadata": {}, "source": "### Testing on test set"}, {"cell_type": "code", "execution_count": null, "id": "e89965aa", "metadata": {}, "outputs": [], "source": "print(\"Evaluate on test data\")\nresults = model.evaluate(x_test, y_test)\nprint(\"test accuracy = \", results[2]);"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.13"}}, "nbformat": 4, "nbformat_minor": 5}