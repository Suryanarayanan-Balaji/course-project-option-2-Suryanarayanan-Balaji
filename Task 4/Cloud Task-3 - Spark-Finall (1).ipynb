{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00a9e2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "\n",
    "import findspark\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.ml import Pipeline,Transformer\n",
    "from pyspark.ml.feature import Imputer,StandardScaler,StringIndexer,OneHotEncoder, VectorAssembler\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38aed979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/11/28 08:43:14 INFO org.apache.spark.SparkEnv: Registering MapOutputTracker\n",
      "22/11/28 08:43:14 INFO org.apache.spark.SparkEnv: Registering BlockManagerMaster\n",
      "22/11/28 08:43:14 INFO org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "22/11/28 08:43:14 INFO org.apache.spark.SparkEnv: Registering OutputCommitCoordinator\n"
     ]
    }
   ],
   "source": [
    "#creating spark session\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"MQTT\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark = SparkSession.builder.appName(\"mqttProject\").getOrCreate()\n",
    "sc    = spark.sparkContext\n",
    "\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2338b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train = spark.read.csv( (\"gs://dataproc-staging-us-west3-650974721448-eojcphee/train70_augmented.csv\"),header=True, inferSchema= True)\n",
    "test = spark.read.csv( (\"gs://dataproc-staging-us-west3-650974721448-eojcphee/test30_augmented.csv\"),header=True, inferSchema= True)\n",
    "DF = train.union(test)\n",
    "DF = DF.toDF(*(c.replace('.', '_') for c in DF.columns))\n",
    "train = train.toDF(*(c.replace('.', '_') for c in train.columns))\n",
    "test = test.toDF(*(c.replace('.', '_') for c in test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d011dff-5433-4eb4-a25e-07d417449e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove= [ \"mqtt_hdrflags\", \"tcp_flags\", 'mqtt_conack_flags','mqtt_conflags','mqtt_msg',\n",
    "        'mqtt_protoname']\n",
    "train = train.drop(\"mqtt_hdrflags\", \"tcp_flags\", 'mqtt_conack_flags','mqtt_conflags','mqtt_msg',\n",
    "        'mqtt_protoname')\n",
    "test = test.drop(\"mqtt_hdrflags\", \"tcp_flags\", 'mqtt_conack_flags','mqtt_conflags','mqtt_msg',\n",
    "        'mqtt_protoname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1d72484-199d-4c08-b318-b6421549e1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.limit(10000)\n",
    "test = test.limit(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "536e0b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [feature[0] for feature in train.dtypes if feature[1] not in ('string')]\n",
    "string_features = [feature[0] for feature in train.dtypes if feature[1] in ('string')]\n",
    "to_drop =  [\"mqtt_conflag_cleansess\",\"mqtt_proto_len\",\"mqtt_conflag_passwd\",\"mqtt_qos\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a29e526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['tcp_time_delta','tcp_len','mqtt_conack_flags','mqtt_conack_flags_reserved','mqtt_conack_flags_sp',\n",
    " 'mqtt_conack_val','mqtt_conflag_cleansess','mqtt_conflag_passwd','mqtt_conflag_qos','mqtt_conflag_reserved',\n",
    " 'mqtt_conflag_retain','mqtt_conflag_uname','mqtt_conflag_willflag','mqtt_conflags','mqtt_dupflag', \n",
    " 'mqtt_kalive', 'mqtt_len','mqtt_msg','mqtt_msgid', 'mqtt_msgtype', 'mqtt_proto_len', 'mqtt_qos', 'mqtt_retain',\n",
    " 'mqtt_sub_qos', 'mqtt_suback_qos', 'mqtt_ver', 'mqtt_willmsg', 'mqtt_willmsg_len', 'mqtt_willtopic', 'mqtt_willtopic_len',\n",
    " 'target']\n",
    "\n",
    "# nominal_cols = ['mqtt_conack_flags','mqtt_conflags', 'mqtt_msg', 'mqtt_protoname']\n",
    "nominal_cols = []\n",
    "\n",
    "continuous_cols = ['tcp_time_delta', 'tcp_len', 'mqtt_conack_flags_reserved', 'mqtt_conack_flags_sp', 'mqtt_conack_val',\n",
    " 'mqtt_conflag_cleansess', 'mqtt_conflag_passwd', 'mqtt_conflag_qos', 'mqtt_conflag_reserved', 'mqtt_conflag_retain',\n",
    " 'mqtt_conflag_uname', 'mqtt_conflag_willflag', 'mqtt_dupflag', 'mqtt_kalive', 'mqtt_len', 'mqtt_msgid',\n",
    " 'mqtt_msgtype', 'mqtt_proto_len', 'mqtt_qos', 'mqtt_retain', 'mqtt_sub_qos', 'mqtt_suback_qos', 'mqtt_ver',\n",
    " 'mqtt_willmsg', 'mqtt_willmsg_len', 'mqtt_willtopic', 'mqtt_willtopic_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b3ddcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutcomeCreater_binary(Transformer): # this defines a transformer that creates the outcome column\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "  \n",
    "    def _transform(self, dataset):\n",
    "        label_to_binary = udf(lambda name: 0.0 if name == 'legitimate' else 1.0)\n",
    "        output_df = dataset.withColumn('outcome', label_to_binary(col('target'))).drop(\"target\")  \n",
    "        output_df = output_df.withColumn('outcome', col('outcome').cast(DoubleType()))\n",
    "        return output_df\n",
    "    \n",
    "class OutcomeCreater_multi(Transformer): # this defines a transformer that creates the outcome column\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "  \n",
    "    def _transform(self, dataset):\n",
    "        label_to_multiple = udf(lambda name: 0.0 if name == 'legitimate' else (1.0 if name == \"flood\" else(2.0 if name == \"dos\" else(3.0 if name == \"bruteforce\" else(4.0 if name == \"slowite\" else (5.0))))))\n",
    "        output_df = dataset.withColumn('outcome', label_to_multiple(col('target'))).drop(\"target\")  \n",
    "        output_df = output_df.withColumn('outcome', col('outcome').cast(DoubleType()))\n",
    "        return output_df\n",
    "        \n",
    "class FeatureTypeCaster(Transformer): # this transformer will cast the columns as appropriate types  \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        output_df = dataset\n",
    "        for col_name in continuous_cols:\n",
    "            output_df = output_df.withColumn(col_name,col(col_name).cast(DoubleType()))\n",
    "\n",
    "        return output_df\n",
    "    \n",
    "class ColumnDropper(Transformer): # this transformer drops unnecessary columns\n",
    "    def __init__(self, columns_to_drop = None):\n",
    "        super().__init__()\n",
    "        self.columns_to_drop=columns_to_drop\n",
    "    def _transform(self, dataset):\n",
    "        output_df = dataset\n",
    "        for col_name in self.columns_to_drop:\n",
    "            output_df = output_df.drop(col_name)\n",
    "            \n",
    "        return output_df\n",
    "    \n",
    "def get_preprocess_pipeline(classification):\n",
    "    # Stage where columns are casted as appropriate types\n",
    "    stage_typecaster = FeatureTypeCaster()\n",
    "\n",
    "    # Stage where nominal columns are transformed to index columns using StringIndexer\n",
    "    nominal_id_cols = [x+\"_index\" for x in nominal_cols]\n",
    "    nominal_onehot_cols = [x+\"_encoded\" for x in nominal_cols]\n",
    "    stage_nominal_indexer = StringIndexer(inputCols = nominal_cols, outputCols = nominal_id_cols )\n",
    "    \n",
    "    # Stage where the index columns are further transformed using OneHotEncoder\n",
    "    stage_nominal_onehot_encoder = OneHotEncoder(inputCols=nominal_id_cols, outputCols=nominal_onehot_cols)\n",
    "\n",
    "    # Stage where all relevant features are assembled into a vector (and dropping a few)\n",
    "    feature_cols = continuous_cols+nominal_onehot_cols\n",
    "    corelated_cols_to_remove = to_drop\n",
    "    \n",
    "    for col_name in corelated_cols_to_remove:\n",
    "        feature_cols.remove(col_name)\n",
    "    stage_vector_assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"vectorized_features\")\n",
    "\n",
    "    # Stage where we scale the columns\n",
    "    stage_scaler = StandardScaler(inputCol= 'vectorized_features', outputCol= 'features')\n",
    "    \n",
    "\n",
    "    # Stage for creating the outcome column representing whether there is attack\n",
    "    if(classification == \"binary\"): \n",
    "        stage_outcome = OutcomeCreater_binary()\n",
    "    else:\n",
    "        stage_outcome = OutcomeCreater_multi()\n",
    "\n",
    "    # Removing all unnecessary columbs, only keeping the 'features' and 'outcome' columns\n",
    "    stage_column_dropper = ColumnDropper(columns_to_drop = nominal_cols+nominal_id_cols+\n",
    "        nominal_onehot_cols + continuous_cols + ['vectorized_features'])\n",
    "    \n",
    "    pipeline = Pipeline(stages=[stage_typecaster,stage_nominal_indexer,stage_nominal_onehot_encoder,\n",
    "        stage_vector_assembler,stage_scaler,stage_outcome,stage_column_dropper])\n",
    "    \n",
    "    return pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d07b64",
   "metadata": {},
   "source": [
    "### Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d87035f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/11/28 08:44:34 WARN org.apache.spark.sql.catalyst.util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "preprocess_pipeline = get_preprocess_pipeline(\"multi\")\n",
    "preprocess_pipeline_model = preprocess_pipeline.fit(train)\n",
    "\n",
    "train_df = preprocess_pipeline_model.transform(train)\n",
    "test_df = preprocess_pipeline_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "043458df-4b62-4b59-98bb-753b7f5e8ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.limit(10000)\n",
    "test_df = test_df.limit(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428bed74",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb30efd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(featuresCol=\"features\",labelCol = \"outcome\")\n",
    "dt_model = dt.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9388d89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy = 74.1%\n",
      "Test accuracy = 72.3%\n"
     ]
    }
   ],
   "source": [
    "dt_prediction_train = dt_model.transform(train_df)\n",
    "dt_prediction_test = dt_model.transform(test_df)\n",
    "\n",
    "dt_accuracy_train = (dt_prediction_train.filter(\n",
    "    dt_prediction_train.outcome == dt_prediction_train.prediction).count() / \n",
    "    float(dt_prediction_train.count()))\n",
    "dt_accuracy_test = (dt_prediction_test.filter(\n",
    "    dt_prediction_test.outcome == dt_prediction_test.prediction).count()\n",
    "    / float(dt_prediction_test.count()))\n",
    "\n",
    "print(f\"Train accuracy = {np.round(dt_accuracy_train*100,2)}%\")\n",
    "print(f\"Test accuracy = {np.round(dt_accuracy_test*100,2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa45f1ab",
   "metadata": {},
   "source": [
    "#### Hyper Parameter Tuning with Crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb002f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy after tuning= 72.90\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'outcome')\n",
    "\n",
    "dt_paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(dt.maxDepth, [5, 10])# maximum depth for each tree\n",
    "             .addGrid(dt.maxBins,[5,  10])\n",
    "             .build())\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='outcome',predictionCol='prediction', metricName=\"accuracy\")\n",
    "\n",
    "dt_cv = CrossValidator(estimator=dt, estimatorParamMaps=dt_paramGrid, \n",
    "                    evaluator=evaluator, numFolds=5)\n",
    "\n",
    "dt_cv_model = dt_cv.fit(train_df)\n",
    "\n",
    "dt_cv_prediction_test = dt_cv_model.transform(test_df)\n",
    "\n",
    "accuracy = evaluator.evaluate(dt_cv_prediction_test)\n",
    "\n",
    "print(f\"Test accuracy after tuning= {accuracy * 100 :1.2f}\")   ### After tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7febfadb",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "453e660a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/11/28 08:45:24 WARN com.github.fommil.netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "22/11/28 08:45:24 WARN com.github.fommil.netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "[Stage 1079:=========================================>            (13 + 4) / 17]\r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "\n",
    "lr = LogisticRegression(labelCol = 'outcome')\n",
    "\n",
    "\n",
    "lrModel = lr.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06529e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 65.10000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "predictions = lrModel.transform(test_df)\n",
    "\n",
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"outcome\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3567cf85",
   "metadata": {},
   "source": [
    "#### Hyper Parameter Tuning with Crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "370fd064",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20cf5011",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5814:============================================>         (14 + 3) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy after tuning= 65.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create ParamGrid for Cross Validation\n",
    "lr_paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.01,  2.0])\n",
    "             .addGrid(lr.maxIter, [3, 10])\n",
    "             .build())\n",
    "\n",
    "\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'outcome')\n",
    "\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', \n",
    "    labelCol='outcome', metricName='accuracy')\n",
    "\n",
    "lr_cv = CrossValidator(estimator=lr, estimatorParamMaps=lr_paramGrid, \n",
    "                    evaluator=evaluator, numFolds=5)\n",
    "\n",
    "lr_cv_model = lr_cv.fit(train_df)\n",
    "\n",
    "lr_cv_prediction_test = lr_cv_model.transform(test_df)\n",
    "\n",
    "accuracy = evaluator.evaluate(lr_cv_prediction_test)\n",
    "\n",
    "print(f\"Test accuracy after tuning= {accuracy * 100 :1.2f}\")   ### After tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62b77cc",
   "metadata": {},
   "source": [
    "### Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8eb8946",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "preprocess_pipeline = get_preprocess_pipeline(\"binary\")\n",
    "preprocess_pipeline_model = preprocess_pipeline.fit(train)\n",
    "\n",
    "train_df = preprocess_pipeline_model.transform(train)\n",
    "test_df = preprocess_pipeline_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc72119d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df= train_df.limit(14000)\n",
    "test_df = test_df.limit(6000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bbe957",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a639daea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(featuresCol=\"features\",labelCol = \"outcome\")\n",
    "dt_model = dt.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d51003eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy = 91.11%, test accuracy = 90.7%, AUC = 0.91\n"
     ]
    }
   ],
   "source": [
    "dt_prediction_train = dt_model.transform(train_df)\n",
    "dt_prediction_test = dt_model.transform(test_df)\n",
    "\n",
    "dt_accuracy_train = (dt_prediction_train.filter(\n",
    "    dt_prediction_train.outcome == dt_prediction_train.prediction).count() / \n",
    "    float(dt_prediction_train.count()))\n",
    "dt_accuracy_test = (dt_prediction_test.filter(\n",
    "    dt_prediction_test.outcome == dt_prediction_test.prediction).count()\n",
    "    / float(dt_prediction_test.count()))\n",
    "\n",
    "dt_auc = evaluator.evaluate(dt_prediction_test)\n",
    "\n",
    "print(f\"Train accuracy = {np.round(dt_accuracy_train*100,2)}%, test accuracy = {np.round(dt_accuracy_test*100,2)}%, AUC = {np.round(dt_auc,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46efda7f",
   "metadata": {},
   "source": [
    "##### Tuning with crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38c3a738",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'outcome')\n",
    "\n",
    "dt_paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(dt.maxDepth, [5, 10])# maximum depth for each tree\n",
    "             .addGrid(dt.maxBins,[5,  10])\n",
    "             .build())\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction', \n",
    "    labelCol='outcome', metricName='areaUnderROC')\n",
    "\n",
    "dt_cv = CrossValidator(estimator=dt, estimatorParamMaps=dt_paramGrid, \n",
    "                    evaluator=evaluator, numFolds=5)\n",
    "\n",
    "dt_cv_model = dt_cv.fit(train_df)\n",
    "\n",
    "dt_cv_prediction_test = dt_cv_model.transform(test_df)\n",
    "\n",
    "\n",
    "dt_cv_auc = evaluator.evaluate(dt_cv_prediction_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3bb2d928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cross-validation and parameter tuning, AUC=0.91\n",
      "After cross-validation and parameter tuning, AUC=0.92\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before cross-validation and parameter tuning, AUC={np.round(dt_auc,2)}\")\n",
    "print(f\"After cross-validation and parameter tuning, AUC={np.round(dt_cv_auc,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de81bf6f",
   "metadata": {},
   "source": [
    "### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfc257d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/11/28 08:47:32 ERROR breeze.optimize.OWLQN: Failure! Resetting history: breeze.optimize.NaNHistory: \n",
      "22/11/28 08:47:33 ERROR breeze.optimize.OWLQN: Failure! Resetting history: breeze.optimize.NaNHistory: \n",
      "22/11/28 08:47:34 ERROR breeze.optimize.OWLQN: Failure! Resetting history: breeze.optimize.NaNHistory: \n",
      "22/11/28 08:47:35 ERROR breeze.optimize.OWLQN: Failure! Resetting history: breeze.optimize.NaNHistory: \n",
      "22/11/28 08:47:36 ERROR breeze.optimize.OWLQN: Failure! Resetting history: breeze.optimize.NaNHistory: \n",
      "22/11/28 08:47:36 ERROR breeze.optimize.OWLQN: Failure! Resetting history: breeze.optimize.NaNHistory: \n",
      "[Stage 8004:=========================================>            (13 + 4) / 17]\r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "svm = LinearSVC(featuresCol=\"features\",labelCol = \"outcome\")\n",
    "\n",
    "svm_model = svm.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8aa96b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy = 77.64%\n",
      "Test accuracy = 78.9%\n",
      "AUC = 0.81\n"
     ]
    }
   ],
   "source": [
    "# make predictions on training dataset and test data set\n",
    "svm_prediction_train = svm_model.transform(train_df)\n",
    "svm_prediction_test = svm_model.transform(test_df)\n",
    "\n",
    "# calculate train and test accuracy\n",
    "\n",
    "svm_accuracy_train = (svm_prediction_train.filter(\n",
    "    svm_prediction_train.outcome == svm_prediction_train.prediction).count() / \n",
    "    float(svm_prediction_train.count()))\n",
    "svm_accuracy_test = (svm_prediction_test.filter(\n",
    "    svm_prediction_test.outcome == svm_prediction_test.prediction).count()\n",
    "    / float(svm_prediction_test.count()))\n",
    "    \n",
    "# calculate AUC\n",
    "svm_auc = evaluator.evaluate(svm_prediction_test)\n",
    "\n",
    "print(f\"Train accuracy = {np.round(svm_accuracy_train*100,2)}%\")\n",
    "print(f\"Test accuracy = {np.round(svm_accuracy_test*100,2)}%\")\n",
    "print(f\"AUC = {np.round(svm_auc,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc3d3eb",
   "metadata": {},
   "source": [
    "#### Tuning with Crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7085d044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 32805:=====================================>               (12 + 4) / 17]\r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "svm = LinearSVC(featuresCol=\"features\",labelCol = \"outcome\")\n",
    "\n",
    "svm_paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(svm.regParam, [0.01, 0.5, 2.0])# regularization parameter\n",
    "             .addGrid(svm.maxIter, [10, 50, 100])#Number of iterations\n",
    "             .build())\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction', \n",
    "    labelCol='outcome', metricName='areaUnderROC')\n",
    "\n",
    "svm_cv = CrossValidator(estimator=svm, estimatorParamMaps=svm_paramGrid, \n",
    "                    evaluator=evaluator, numFolds=5)\n",
    "\n",
    "svm_cv_model = svm_cv.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad71f689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cross-validation and parameter tuning, AUC=0.81\n",
      "After cross-validation and parameter tuning, AUC=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "svm_cv_prediction_test = svm_cv_model.transform(test_df)\n",
    "\n",
    "svm_cv_auc = evaluator.evaluate(svm_cv_prediction_test)\n",
    "\n",
    "print(f\"Before cross-validation and parameter tuning, AUC={np.round(svm_auc,2)}\")\n",
    "print(f\"After cross-validation and parameter tuning, AUC={np.round(svm_cv_auc,2)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
